"""
dart_crawler.py â€” DART ê³µì‹œ ë‚ ì§œë³„ í¬ë¡¤ë§ + JSON ìºì‹œ
ë°±í…ŒìŠ¤íŠ¸ ì‹œ íŠ¹ì • ë‚ ì§œì˜ ê¸°ì—… ê³µì‹œ ì •ë³´ë¥¼ ìˆ˜ì§‘

DART OpenAPI: https://opendart.fss.or.kr
- ê³µì‹œê²€ìƒ‰: /api/list.json
- Rate limit: ë¶„ë‹¹ 100ê±´ ì´ë‚´
- API í‚¤ í•„ìš”: í™˜ê²½ë³€ìˆ˜ DART_API_KEY ë˜ëŠ” dart_api_key.txt
"""

import os
import json
import logging
import time
from datetime import datetime, timedelta
from typing import List, Dict, Optional

logger = logging.getLogger("backtest.dart_crawler")

DART_BASE_URL = "https://opendart.fss.or.kr/api"

# â”€â”€ ê³µì‹œ ìœ í˜• í•„í„° (ë°±í…ŒìŠ¤íŠ¸ì— ìœ ì˜ë¯¸í•œ ê³µì‹œë§Œ) â”€â”€
IMPORTANT_DISCLOSURE_TYPES = {
    "A": "ì •ê¸°ê³µì‹œ",       # ì‚¬ì—…ë³´ê³ ì„œ, ë¶„ê¸°ë³´ê³ ì„œ
    "B": "ì£¼ìš”ì‚¬í•­ë³´ê³ ",   # ìœ ìƒì¦ì, ì£¼ìš”ê²½ì˜ì‚¬í•­
    "C": "ë°œí–‰ê³µì‹œ",       # ì¦ê¶Œë°œí–‰
    "D": "ì§€ë¶„ê³µì‹œ",       # ëŒ€ëŸ‰ë³´ìœ  ë³€ë™
    "I": "ê±°ë˜ì†Œê³µì‹œ",     # ê±°ë˜ì†Œ ê³µì‹œ
}

# í‚¤ì›Œë“œ ê¸°ë°˜ ê³µì‹œ ì¤‘ìš”ë„ ë¶„ë¥˜
HIGH_IMPACT_KEYWORDS = [
    "ìœ ìƒì¦ì", "ë¬´ìƒì¦ì", "ê°ì", "í•©ë³‘",
    "ë¶„í• ", "ì˜ì—…ì–‘ìˆ˜", "ì˜ì—…ì–‘ë„",
    "ëŒ€í‘œì´ì‚¬ë³€ê²½", "ìµœëŒ€ì£¼ì£¼ë³€ê²½",
    "ë§¤ì¶œì•¡ë˜ëŠ”ì†ìµêµ¬ì¡°", "ì‹¤ì ", "ì ì •ì‹¤ì ",
    "ìê¸°ì£¼ì‹", "ì „í™˜ì‚¬ì±„", "ì‹ ì£¼ì¸ìˆ˜ê¶Œë¶€ì‚¬ì±„",
    "ìƒì¥íì§€", "ê´€ë¦¬ì¢…ëª©",
    "ëŒ€ëŸ‰ë³´ìœ ", "ì„ì›ã†ì£¼ìš”ì£¼ì£¼",
]

MEDIUM_IMPACT_KEYWORDS = [
    "ì‚¬ì—…ë³´ê³ ì„œ", "ë¶„ê¸°ë³´ê³ ì„œ", "ë°˜ê¸°ë³´ê³ ì„œ",
    "ì£¼ìš”ì‚¬í•­", "ì¡°íšŒê³µì‹œ",
    "íƒ€ë²•ì¸ì£¼ì‹", "íˆ¬ìíŒë‹¨",
]


def _get_dart_api_key() -> str:
    """DART API í‚¤ ë¡œë“œ (í™˜ê²½ë³€ìˆ˜ â†’ .env íŒŒì¼ â†’ txt íŒŒì¼)"""
    key = os.getenv("DART_API_KEY", "")
    if key:
        return key
    # .env íŒŒì¼ì—ì„œ ì½ê¸°
    for env_path in [".env", "../.env", "../../.env",
                     os.path.join(os.path.dirname(__file__), "../../.env")]:
        try:
            if os.path.exists(env_path):
                with open(env_path, "r") as f:
                    for line in f:
                        line = line.strip()
                        if line.startswith("DART_API_KEY=") and not line.startswith("#"):
                            val = line.split("=", 1)[1].strip()
                            if val:
                                return val
        except Exception:
            continue
    # txt íŒŒì¼ì—ì„œ ì½ê¸°
    for path in ["dart_api_key.txt", "../dart_api_key.txt", "config/dart_api_key.txt"]:
        if os.path.exists(path):
            with open(path, "r") as f:
                return f.read().strip()
    return ""


def _classify_impact(report_nm: str) -> str:
    """ê³µì‹œ ì œëª©ìœ¼ë¡œ ì˜í–¥ë„ ë¶„ë¥˜"""
    for kw in HIGH_IMPACT_KEYWORDS:
        if kw in report_nm:
            return "HIGH"
    for kw in MEDIUM_IMPACT_KEYWORDS:
        if kw in report_nm:
            return "MEDIUM"
    return "LOW"


def fetch_dart_disclosures(target_date: str,
                           lookback_days: int = 3,
                           corp_cls: str = "Y",
                           cache_dir: str = "backtest/cache/dart") -> List[Dict]:
    """
    íŠ¹ì • ë‚ ì§œ ê¸°ì¤€ DART ê³µì‹œ ì¡°íšŒ

    Parameters:
        target_date: "YYYY-MM-DD" í˜•ì‹
        lookback_days: ë©°ì¹  ì „ë¶€í„° ì¡°íšŒí• ì§€ (ê¸°ë³¸ 3ì¼ â€” ì£¼ë§/ê³µíœ´ì¼ ëŒ€ë¹„)
        corp_cls: Y=ì½”ìŠ¤í”¼, K=ì½”ìŠ¤ë‹¥, "" = ì „ì²´
        cache_dir: ìºì‹œ í´ë”

    Returns:
        [{"corp_name", "report_nm", "rcept_dt", "impact", "type"}, ...]
    """
    os.makedirs(cache_dir, exist_ok=True)
    cache_file = os.path.join(cache_dir, f"{target_date}_{corp_cls}.json")

    # ìºì‹œ í™•ì¸
    if os.path.exists(cache_file):
        with open(cache_file, "r", encoding="utf-8") as f:
            cached = json.load(f)
        logger.info(f"DART ìºì‹œ ë¡œë“œ: {target_date} ({len(cached)}ê±´)")
        return cached

    api_key = _get_dart_api_key()
    if not api_key:
        logger.warning("DART_API_KEY ë¯¸ì„¤ì • â€” ê³µì‹œ ë°ì´í„° ì—†ì´ ì§„í–‰")
        return []

    import requests

    # ë‚ ì§œ ê³„ì‚°
    dt = datetime.strptime(target_date, "%Y-%m-%d")
    bgn_de = (dt - timedelta(days=lookback_days)).strftime("%Y%m%d")
    end_de = dt.strftime("%Y%m%d")

    all_disclosures = []

    # ì½”ìŠ¤í”¼ + ì½”ìŠ¤ë‹¥ ì¡°íšŒ
    markets = [corp_cls] if corp_cls else ["Y", "K"]

    for mkt in markets:
        page = 1
        while page <= 5:  # ìµœëŒ€ 5í˜ì´ì§€ (500ê±´)
            try:
                resp = requests.get(
                    f"{DART_BASE_URL}/list.json",
                    params={
                        "crtfc_key": api_key,
                        "bgn_de": bgn_de,
                        "end_de": end_de,
                        "corp_cls": mkt,
                        "page_no": page,
                        "page_count": 100,
                        "sort": "date",
                        "sort_mth": "desc",
                    },
                    timeout=10,
                )
                data = resp.json()

                if data.get("status") != "000":
                    # 000=ì •ìƒ, 013=ì¡°íšŒëœë°ì´í„°ì—†ìŒ
                    if data.get("status") == "013":
                        break
                    logger.warning(f"DART API ì˜¤ë¥˜: {data.get('message', '')}")
                    break

                items = data.get("list", [])
                if not items:
                    break

                for item in items:
                    report_nm = item.get("report_nm", "")
                    impact = _classify_impact(report_nm)

                    # LOW ì˜í–¥ë„ëŠ” ìŠ¤í‚µ (ë„ˆë¬´ ë§ìŒ)
                    if impact == "LOW":
                        continue

                    all_disclosures.append({
                        "corp_name": item.get("corp_name", ""),
                        "corp_code": item.get("corp_code", ""),
                        "stock_code": item.get("stock_code", ""),
                        "report_nm": report_nm,
                        "rcept_dt": item.get("rcept_dt", ""),
                        "flr_nm": item.get("flr_nm", ""),  # ê³µì‹œ ì œì¶œì¸
                        "type": IMPORTANT_DISCLOSURE_TYPES.get(
                            item.get("pblntf_ty", ""), "ê¸°íƒ€"
                        ),
                        "impact": impact,
                    })

                # ë‹¤ìŒ í˜ì´ì§€
                total_page = data.get("total_page", 1)
                if page >= total_page:
                    break
                page += 1
                time.sleep(0.7)  # Rate limit: ë¶„ë‹¹ 100ê±´

            except Exception as e:
                logger.error(f"DART API í˜¸ì¶œ ì‹¤íŒ¨: {e}")
                break

    # ìºì‹œ ì €ì¥
    with open(cache_file, "w", encoding="utf-8") as f:
        json.dump(all_disclosures, f, ensure_ascii=False, indent=2)

    logger.info(f"DART ê³µì‹œ ìˆ˜ì§‘: {target_date} ({len(all_disclosures)}ê±´)")
    return all_disclosures


def format_dart_for_agent(disclosures: List[Dict]) -> str:
    """DART ê³µì‹œ ë¦¬ìŠ¤íŠ¸ â†’ Agent ì…ë ¥ìš© í…ìŠ¤íŠ¸"""
    if not disclosures:
        return "ìµœê·¼ ì£¼ìš” ê³µì‹œ ì—†ìŒ"

    lines = ["[ìµœê·¼ ì£¼ìš” ê³µì‹œ]"]

    # HIGH ë¨¼ì €
    high = [d for d in disclosures if d["impact"] == "HIGH"]
    medium = [d for d in disclosures if d["impact"] == "MEDIUM"]

    for d in high[:10]:
        lines.append(f"âš ï¸ [{d['rcept_dt']}] {d['corp_name']}: {d['report_nm']}")

    for d in medium[:10]:
        lines.append(f"ğŸ“‹ [{d['rcept_dt']}] {d['corp_name']}: {d['report_nm']}")

    lines.append(f"(HIGH: {len(high)}ê±´, MEDIUM: {len(medium)}ê±´)")
    return "\n".join(lines)


def get_stock_disclosures(disclosures: List[Dict],
                          stock_code: str) -> List[Dict]:
    """íŠ¹ì • ì¢…ëª©ì˜ ê³µì‹œë§Œ í•„í„°"""
    # stock_codeëŠ” 6ìë¦¬ (000020), DARTì—ì„œëŠ” ì• 0 í¬í•¨
    return [d for d in disclosures
            if d.get("stock_code", "").strip() == stock_code.strip()]
