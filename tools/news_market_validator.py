# tools/news_market_validator.py â€” ë‰´ìŠ¤ ê¸´ê¸‰ë„ vs ë¯¸êµ­ ì‹œì¥ ìƒê´€ê´€ê³„ ê²€ì¦
# 2026-03-01 êµ¬í˜„
#
# ëª©ì :
#   ê±°ì‹œê²½ì œ ë¶„ì„ê´€(Agent 1)ì˜ ë‰´ìŠ¤ ê¸´ê¸‰ë„ ì‹œê·¸ë„ì´ ì‹¤ì œ ë¯¸êµ­ ì‹œì¥ íë¦„ê³¼
#   ì¼ì¹˜í•˜ëŠ”ì§€ë¥¼ ê²€ì¦í•œë‹¤. ë§¤ ì‹œê°„ë§ˆë‹¤ ë‰´ìŠ¤ ê¸´ê¸‰ë„ + ë¯¸êµ­ ì§€ìˆ˜ ìŠ¤ëƒ…ìƒ·ì„
#   ê¸°ë¡í•˜ê³ , ì‹œê°„ì´ ì§€ë‚¨ì— ë”°ë¼ "ê¸´ê¸‰ë„ HIGH â†’ ì‹¤ì œ ì‹œì¥ í•˜ë½" ê°™ì€
#   ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•œë‹¤.
#
# ë°ì´í„° íë¦„:
#   job_hourly_news_scan (ë‰´ìŠ¤ ê¸´ê¸‰ë„)
#        +
#   yfinance (S&P500, NASDAQ, VIX ì‹¤ì‹œê°„)
#        â†“
#   MarketSnapshot ê¸°ë¡ (ì‹œê°„ë³„)
#        â†“
#   ìƒê´€ê´€ê³„ ë¶„ì„ â†’ ì¼ì¼ ê²€ì¦ ë¦¬í¬íŠ¸ â†’ í…”ë ˆê·¸ë¨/íŒŒì¼ ì¶œë ¥

import os
import json
import time
import threading
import logging
from datetime import datetime, timedelta
from collections import defaultdict
from pathlib import Path

logger = logging.getLogger(__name__)

try:
    import yfinance as yf
except ImportError:
    yf = None

from tools.utils import safe_float

# â”€â”€ ì„¤ì • â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€

# ì¶”ì í•  ê¸€ë¡œë²Œ ì§€ìˆ˜
TRACKED_INDICES = {
    "SP500": "^GSPC",
    "NASDAQ": "^IXIC",
    "VIX": "^VIX",
    "DOW": "^DJI",
    "WTI": "CL=F",
    "GOLD": "GC=F",
    "DXY": "DX-Y.NYB",
    "USDKRW": "USDKRW=X",
}

# ìŠ¤ëƒ…ìƒ· ë³´ê´€ ê²½ë¡œ
SNAPSHOT_DIR = Path("outputs/news_validation")

# ê¸´ê¸‰ë„ â†’ ìˆ«ì ë§¤í•‘ (ìƒê´€ê´€ê³„ ë¶„ì„ìš©)
URGENCY_NUM = {"NONE": 0, "LOW": 1, "MEDIUM": 2, "HIGH": 3, "CRITICAL": 4}


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  MarketSnapshot â€” ì‹œê°„ë³„ ì‹œì¥ ìŠ¤ëƒ…ìƒ·
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class MarketSnapshot:
    """ì‹œê°„ë³„ ë‰´ìŠ¤ ê¸´ê¸‰ë„ + ì‹œì¥ ì§€ìˆ˜ë¥¼ ê¸°ë¡í•˜ëŠ” êµ¬ì¡°ì²´"""

    def __init__(self, timestamp: str, urgency: str, trend_narrative: str,
                 urgent_items: list, indices: dict):
        self.timestamp = timestamp            # ISO í˜•ì‹
        self.urgency = urgency                # NONE/LOW/MEDIUM/HIGH/CRITICAL
        self.urgency_num = URGENCY_NUM.get(urgency, 0)
        self.trend_narrative = trend_narrative
        self.urgent_items = urgent_items      # ìƒìœ„ ê¸´ê¸‰ ê¸°ì‚¬
        self.indices = indices                # {"SP500": {"price": x, "change_pct": y}, ...}

    def to_dict(self) -> dict:
        return {
            "timestamp": self.timestamp,
            "urgency": self.urgency,
            "urgency_num": self.urgency_num,
            "trend_narrative": self.trend_narrative,
            "urgent_items": self.urgent_items,
            "indices": self.indices,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ValidationBuffer â€” ìŠ¤ëƒ…ìƒ· íƒ€ì„ë¼ì¸ ê´€ë¦¬
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class ValidationBuffer:
    """
    ì‹œê°„ë³„ ìŠ¤ëƒ…ìƒ·ì„ ì¶•ì í•˜ê³ , ì¼ì¼ ê²€ì¦ ë¶„ì„ì„ ìˆ˜í–‰í•œë‹¤.
    ë©”ëª¨ë¦¬ + íŒŒì¼ ì´ì¤‘ ì €ì¥ (ì¬ì‹œì‘ ë³µì› ê°€ëŠ¥).
    """

    def __init__(self, max_days: int = 90):
        self._snapshots: list[MarketSnapshot] = []
        self._lock = threading.Lock()
        self._max_seconds = max_days * 86400
        SNAPSHOT_DIR.mkdir(parents=True, exist_ok=True)

    def add_snapshot(self, snapshot: MarketSnapshot):
        """ìŠ¤ëƒ…ìƒ· ì¶”ê°€ + íŒŒì¼ ì €ì¥"""
        with self._lock:
            self._snapshots.append(snapshot)
            self._cleanup_old()
        self._persist_snapshot(snapshot)

    def _cleanup_old(self):
        """max_days ì´ˆê³¼ ìŠ¤ëƒ…ìƒ· ì‚­ì œ"""
        cutoff = time.time() - self._max_seconds
        self._snapshots = [
            s for s in self._snapshots
            if datetime.fromisoformat(s.timestamp).timestamp() >= cutoff
        ]

    def _persist_snapshot(self, snapshot: MarketSnapshot):
        """ì¼ë³„ JSONL íŒŒì¼ì— ìŠ¤ëƒ…ìƒ·ì„ ì¶”ê°€ ì €ì¥"""
        try:
            date_str = snapshot.timestamp[:10]  # YYYY-MM-DD
            filepath = SNAPSHOT_DIR / f"snapshots_{date_str}.jsonl"
            with open(filepath, "a", encoding="utf-8") as f:
                f.write(json.dumps(snapshot.to_dict(), ensure_ascii=False) + "\n")
        except Exception as e:
            logger.warning(f"ìŠ¤ëƒ…ìƒ· ì €ì¥ ì‹¤íŒ¨: {e}")

    def get_snapshots(self, hours: int = 24) -> list[MarketSnapshot]:
        """ìµœê·¼ Nì‹œê°„ ìŠ¤ëƒ…ìƒ· ë°˜í™˜"""
        cutoff_ts = (datetime.now() - timedelta(hours=hours)).isoformat()
        with self._lock:
            return [s for s in self._snapshots if s.timestamp >= cutoff_ts]

    def load_from_file(self, date_str: str = None):
        """íŒŒì¼ì—ì„œ ìŠ¤ëƒ…ìƒ· ë³µì› (ì„œë¹„ìŠ¤ ì¬ì‹œì‘ ì‹œ)"""
        if date_str is None:
            date_str = datetime.now().strftime("%Y-%m-%d")
        filepath = SNAPSHOT_DIR / f"snapshots_{date_str}.jsonl"
        if not filepath.exists():
            return
        try:
            with open(filepath, "r", encoding="utf-8") as f:
                for line in f:
                    data = json.loads(line.strip())
                    snapshot = MarketSnapshot(
                        timestamp=data["timestamp"],
                        urgency=data["urgency"],
                        trend_narrative=data.get("trend_narrative", ""),
                        urgent_items=data.get("urgent_items", []),
                        indices=data.get("indices", {}),
                    )
                    self._snapshots.append(snapshot)
            logger.info(f"ìŠ¤ëƒ…ìƒ· ë³µì›: {filepath} ({len(self._snapshots)}ê±´)")
        except Exception as e:
            logger.warning(f"ìŠ¤ëƒ…ìƒ· ë³µì› ì‹¤íŒ¨: {e}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  CorrelationAnalyzer â€” ë‰´ìŠ¤ vs ì‹œì¥ ìƒê´€ê´€ê³„ ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

class CorrelationAnalyzer:
    """
    ìŠ¤ëƒ…ìƒ· íƒ€ì„ë¼ì¸ì—ì„œ ë‰´ìŠ¤ ê¸´ê¸‰ë„ì™€ ì‹œì¥ ì›€ì§ì„ì˜ ìƒê´€ê´€ê³„ë¥¼ ë¶„ì„í•œë‹¤.

    í•µì‹¬ ë¶„ì„:
    1) ê¸´ê¸‰ë„ ë³€í™” ì‹œì  ì „í›„ ì‹œì¥ ë°˜ì‘ (ì´ë²¤íŠ¸ ìŠ¤í„°ë””)
    2) ì‹œê°„ëŒ€ë³„ ê¸´ê¸‰ë„ vs ì§€ìˆ˜ ë³€ë™ë¥  ë°©í–¥ ì¼ì¹˜ë„
    3) ì¼ì¼ ìš”ì•½ ë¦¬í¬íŠ¸ ìƒì„±
    """

    def __init__(self, buffer: ValidationBuffer):
        self._buffer = buffer

    def analyze_event_impact(self, hours_back: int = 24) -> list[dict]:
        """
        ê¸´ê¸‰ë„ê°€ ë³€í™”í•œ ì‹œì ì„ ì°¾ì•„, ê·¸ ì „í›„ ì‹œì¥ ë³€ë™ì„ ë¶„ì„í•œë‹¤.
        'ê¸´ê¸‰ë„ HIGH ë°œìƒ í›„ 1ì‹œê°„ ë‚´ S&P 500 -1.2%' ê°™ì€ ì¸ì‚¬ì´íŠ¸.

        Returns:
        [
            {
                "event_time": str,
                "urgency_from": str, "urgency_to": str,
                "market_reaction": {"SP500": -1.2, "VIX": +3.5, ...},
                "aligned": bool,  # ì˜ˆìƒëŒ€ë¡œ ë°˜ì‘í–ˆëŠ”ì§€
            },
            ...
        ]
        """
        snapshots = self._buffer.get_snapshots(hours_back)
        if len(snapshots) < 2:
            return []

        events = []
        for i in range(1, len(snapshots)):
            prev = snapshots[i - 1]
            curr = snapshots[i]

            # ê¸´ê¸‰ë„ê°€ ë³€í™”í•œ ì‹œì ë§Œ ë¶„ì„
            if prev.urgency == curr.urgency:
                continue

            # ì‹œì¥ ë°˜ì‘ ê³„ì‚° (í˜„ì¬ ìŠ¤ëƒ…ìƒ· vs ì´ì „ ìŠ¤ëƒ…ìƒ·ì˜ ì§€ìˆ˜ ë³€í™”)
            market_reaction = {}
            for idx_name in ["SP500", "NASDAQ", "VIX", "DOW"]:
                prev_price = prev.indices.get(idx_name, {}).get("price", 0)
                curr_price = curr.indices.get(idx_name, {}).get("price", 0)
                if prev_price > 0 and curr_price > 0:
                    change_pct = (curr_price - prev_price) / prev_price * 100
                    market_reaction[idx_name] = round(change_pct, 3)

            # ê¸´ê¸‰ë„ ìƒìŠ¹ â†’ ì‹œì¥ í•˜ë½ì´ë©´ "aligned"
            urgency_increased = (
                URGENCY_NUM.get(curr.urgency, 0) > URGENCY_NUM.get(prev.urgency, 0)
            )
            sp500_dropped = market_reaction.get("SP500", 0) < 0
            vix_spiked = market_reaction.get("VIX", 0) > 0

            if urgency_increased:
                aligned = sp500_dropped or vix_spiked
            else:
                # ê¸´ê¸‰ë„ í•˜ë½ â†’ ì‹œì¥ ë°˜ë“±ì´ë©´ aligned
                aligned = market_reaction.get("SP500", 0) > 0

            events.append({
                "event_time": curr.timestamp,
                "urgency_from": prev.urgency,
                "urgency_to": curr.urgency,
                "trend_narrative": curr.trend_narrative,
                "market_reaction": market_reaction,
                "aligned": aligned,
            })

        return events

    def calc_direction_match_rate(self, hours_back: int = 24) -> dict:
        """
        ì‹œê°„ëŒ€ë³„ ê¸´ê¸‰ë„ ë°©í–¥ê³¼ ì‹œì¥ ë°©í–¥ì˜ ì¼ì¹˜ìœ¨ì„ ê³„ì‚°í•œë‹¤.

        ë¡œì§:
        - ê¸´ê¸‰ë„ â‰¥ MEDIUM â†’ ì‹œì¥ í•˜ë½(SP500â†“ or VIXâ†‘)ì´ë©´ ì¼ì¹˜
        - ê¸´ê¸‰ë„ â‰¤ LOW â†’ ì‹œì¥ ì•ˆì •(SP500â†‘ or VIXâ†“)ì´ë©´ ì¼ì¹˜

        Returns:
        {
            "total_points": int,
            "match_count": int,
            "match_rate": float,  # 0.0 ~ 1.0
            "details": [...]
        }
        """
        snapshots = self._buffer.get_snapshots(hours_back)
        if len(snapshots) < 2:
            return {"total_points": 0, "match_count": 0, "match_rate": 0.0, "details": []}

        match_count = 0
        total = 0
        details = []

        for i in range(1, len(snapshots)):
            curr = snapshots[i]
            prev = snapshots[i - 1]

            sp500_now = curr.indices.get("SP500", {}).get("price", 0)
            sp500_prev = prev.indices.get("SP500", {}).get("price", 0)
            vix_now = curr.indices.get("VIX", {}).get("price", 0)
            vix_prev = prev.indices.get("VIX", {}).get("price", 0)

            if sp500_prev <= 0 or sp500_now <= 0:
                continue

            sp500_change = (sp500_now - sp500_prev) / sp500_prev * 100
            vix_change = ((vix_now - vix_prev) / vix_prev * 100) if vix_prev > 0 else 0

            news_bearish = curr.urgency_num >= 2  # MEDIUM ì´ìƒ
            market_bearish = sp500_change < -0.1 or vix_change > 1.0

            matched = (news_bearish == market_bearish)
            if matched:
                match_count += 1
            total += 1

            details.append({
                "time": curr.timestamp,
                "urgency": curr.urgency,
                "sp500_chg": round(sp500_change, 3),
                "vix_chg": round(vix_change, 3),
                "news_bearish": news_bearish,
                "market_bearish": market_bearish,
                "matched": matched,
            })

        rate = match_count / max(total, 1)
        return {
            "total_points": total,
            "match_count": match_count,
            "match_rate": round(rate, 3),
            "details": details,
        }

    def generate_daily_report(self) -> dict:
        """
        ì¼ì¼ ê²€ì¦ ë¦¬í¬íŠ¸ë¥¼ ìƒì„±í•œë‹¤.

        Returns:
        {
            "date": str,
            "summary": str,           # í•œì¤„ ìš”ì•½
            "match_rate_24h": float,   # 24ì‹œê°„ ë°©í–¥ ì¼ì¹˜ìœ¨
            "match_rate_12h": float,
            "events": [...],           # ê¸´ê¸‰ë„ ë³€í™” ì´ë²¤íŠ¸ ë¶„ì„
            "timeline": [...],         # ì‹œê°„ë³„ íƒ€ì„ë¼ì¸
            "conclusion": str,         # ê²°ë¡ 
        }
        """
        events = self.analyze_event_impact(24)
        match_24h = self.calc_direction_match_rate(24)
        match_12h = self.calc_direction_match_rate(12)
        snapshots = self._buffer.get_snapshots(24)

        # íƒ€ì„ë¼ì¸ êµ¬ì„±
        timeline = []
        for s in snapshots:
            sp500 = s.indices.get("SP500", {})
            vix = s.indices.get("VIX", {})
            timeline.append({
                "time": s.timestamp[11:16],  # HH:MM
                "urgency": s.urgency,
                "sp500": sp500.get("price", 0),
                "sp500_chg": sp500.get("change_pct", 0),
                "vix": vix.get("price", 0),
                "narrative": s.trend_narrative[:60] if s.trend_narrative else "",
            })

        # ê²°ë¡  ìƒì„±
        rate = match_24h["match_rate"]
        if rate >= 0.8:
            conclusion = f"ë‰´ìŠ¤ ì‹œê·¸ë„ê³¼ ì‹œì¥ íë¦„ ë†’ì€ ì¼ì¹˜ ({rate:.0%}). Agent 1 ë¶„ì„ ì‹ ë¢°ë„ ë†’ìŒ."
        elif rate >= 0.6:
            conclusion = f"ë‰´ìŠ¤ ì‹œê·¸ë„ê³¼ ì‹œì¥ íë¦„ ë³´í†µ ì¼ì¹˜ ({rate:.0%}). ë¶€ë¶„ì  ì‹ ë¢° ê°€ëŠ¥."
        elif rate >= 0.4:
            conclusion = f"ë‰´ìŠ¤ ì‹œê·¸ë„ê³¼ ì‹œì¥ íë¦„ ë‚®ì€ ì¼ì¹˜ ({rate:.0%}). í‚¤ì›Œë“œ ê°€ì¤‘ì¹˜ ì¡°ì • í•„ìš”."
        elif len(snapshots) < 3:
            conclusion = "ë°ì´í„° ë¶€ì¡± â€” ì¶”ê°€ ìˆ˜ì§‘ í•„ìš”."
        else:
            conclusion = f"ë‰´ìŠ¤ ì‹œê·¸ë„ê³¼ ì‹œì¥ íë¦„ ë¶ˆì¼ì¹˜ ({rate:.0%}). ë¶„ì„ ë¡œì§ ì¬ê²€í†  í•„ìš”."

        # ìš”ì•½
        event_count = len(events)
        aligned_count = sum(1 for e in events if e["aligned"])
        summary = (
            f"24ì‹œê°„ ì¼ì¹˜ìœ¨ {rate:.0%} | "
            f"ì´ë²¤íŠ¸ {event_count}ê±´ ì¤‘ {aligned_count}ê±´ ì¼ì¹˜ | "
            f"ìŠ¤ëƒ…ìƒ· {len(snapshots)}ê°œ"
        )

        return {
            "date": datetime.now().strftime("%Y-%m-%d"),
            "summary": summary,
            "match_rate_24h": match_24h["match_rate"],
            "match_rate_12h": match_12h["match_rate"],
            "events": events,
            "direction_details": match_24h["details"],
            "timeline": timeline,
            "conclusion": conclusion,
        }


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ì‹œì¥ ì§€ìˆ˜ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def fetch_index_snapshot() -> dict:
    """
    í˜„ì¬ ë¯¸êµ­ ì‹œì¥ ì£¼ìš” ì§€ìˆ˜ ê°€ê²©ì„ yfinanceë¡œ ìˆ˜ì§‘í•œë‹¤.
    ë‰´ìŠ¤ ìŠ¤ìº”ê³¼ ë™ì‹œì— í˜¸ì¶œë˜ì–´ ìŠ¤ëƒ…ìƒ·ì— í¬í•¨ë¨.

    Returns: {"SP500": {"price": x, "change_pct": y}, ...}
    """
    if yf is None:
        return {}

    indices = {}
    for name, symbol in TRACKED_INDICES.items():
        try:
            ticker = yf.Ticker(symbol)
            df = ticker.history(period="2d", interval="1d")
            if df.empty or len(df) < 1:
                indices[name] = {"price": 0, "change_pct": 0}
                continue

            latest = df.iloc[-1]
            close = safe_float(latest["Close"])

            if len(df) >= 2:
                prev = df.iloc[-2]
                prev_close = safe_float(prev["Close"])
                change_pct = ((close - prev_close) / prev_close * 100) if prev_close > 0 else 0
            else:
                change_pct = 0

            indices[name] = {
                "price": round(close, 2),
                "change_pct": round(change_pct, 3),
                "date": str(df.index[-1].date()),
            }
        except Exception as e:
            logger.debug(f"ì§€ìˆ˜ ìŠ¤ëƒ…ìƒ· ì‹¤íŒ¨ ({name}): {e}")
            indices[name] = {"price": 0, "change_pct": 0}

    return indices


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  ì‹±ê¸€í„´ + ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

_validation_buffer: ValidationBuffer | None = None
_correlation_analyzer: CorrelationAnalyzer | None = None
_singleton_lock = threading.Lock()


def get_validation_buffer() -> ValidationBuffer:
    """ValidationBuffer ì‹±ê¸€í„´"""
    global _validation_buffer
    with _singleton_lock:
        if _validation_buffer is None:
            _validation_buffer = ValidationBuffer(max_days=7)
            # ì˜¤ëŠ˜ì ìŠ¤ëƒ…ìƒ· íŒŒì¼ì—ì„œ ë³µì› ì‹œë„
            _validation_buffer.load_from_file()
        return _validation_buffer


def get_correlation_analyzer() -> CorrelationAnalyzer:
    """CorrelationAnalyzer ì‹±ê¸€í„´"""
    global _correlation_analyzer
    with _singleton_lock:
        if _correlation_analyzer is None:
            _correlation_analyzer = CorrelationAnalyzer(get_validation_buffer())
        return _correlation_analyzer


def record_hourly_snapshot(urgency: str, trend_narrative: str,
                           urgent_items: list) -> MarketSnapshot:
    """
    ì‹œê°„ë³„ ìŠ¤ëƒ…ìƒ·ì„ ê¸°ë¡í•œë‹¤.
    main.pyì˜ job_hourly_news_scan() ì™„ë£Œ í›„ í˜¸ì¶œë¨.

    1) ë¯¸êµ­ ì‹œì¥ ì§€ìˆ˜ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘ (yfinance)
    2) ë‰´ìŠ¤ ê¸´ê¸‰ë„ ì •ë³´ì™€ í•©ì³ì„œ ìŠ¤ëƒ…ìƒ· ìƒì„±
    3) ValidationBufferì— ì €ì¥

    Returns: ìƒì„±ëœ MarketSnapshot
    """
    indices = fetch_index_snapshot()

    snapshot = MarketSnapshot(
        timestamp=datetime.now().isoformat(),
        urgency=urgency,
        trend_narrative=trend_narrative,
        urgent_items=urgent_items,
        indices=indices,
    )

    buf = get_validation_buffer()
    buf.add_snapshot(snapshot)

    logger.info(
        f"[ì‹œì¥ê²€ì¦] ìŠ¤ëƒ…ìƒ· ê¸°ë¡ â€” ê¸´ê¸‰ë„ {urgency} | "
        f"SP500 {indices.get('SP500', {}).get('price', '?')} | "
        f"VIX {indices.get('VIX', {}).get('price', '?')}"
    )

    return snapshot


def generate_validation_report() -> dict:
    """ì¼ì¼ ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„± (main.pyì˜ ì¼ì¼ ë¦¬í¬íŠ¸ jobì—ì„œ í˜¸ì¶œ)"""
    analyzer = get_correlation_analyzer()
    return analyzer.generate_daily_report()


def format_validation_report_telegram(report: dict) -> str:
    """ê²€ì¦ ë¦¬í¬íŠ¸ë¥¼ í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ í˜•ì‹ìœ¼ë¡œ ë³€í™˜"""
    lines = [
        f"ğŸ“Š ë‰´ìŠ¤-ì‹œì¥ ê²€ì¦ ë¦¬í¬íŠ¸ ({report['date']})",
        f"",
        f"ì¼ì¹˜ìœ¨: 24h {report['match_rate_24h']:.0%} | 12h {report['match_rate_12h']:.0%}",
        f"",
    ]

    # ì´ë²¤íŠ¸ ìš”ì•½
    events = report.get("events", [])
    if events:
        lines.append(f"âš¡ ê¸´ê¸‰ë„ ë³€í™” ì´ë²¤íŠ¸ ({len(events)}ê±´):")
        for ev in events[:5]:
            marker = "âœ…" if ev["aligned"] else "âŒ"
            sp500_chg = ev["market_reaction"].get("SP500", 0)
            lines.append(
                f"  {marker} {ev['urgency_from']}â†’{ev['urgency_to']} | "
                f"S&P500 {sp500_chg:+.2f}%"
            )
        lines.append("")

    # ê²°ë¡ 
    lines.append(f"ğŸ’¡ {report['conclusion']}")

    return "\n".join(lines)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
#  í…ŒìŠ¤íŠ¸ ë¸”ë¡
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    print("=" * 60)
    print("  ë‰´ìŠ¤-ì‹œì¥ ìƒê´€ê´€ê³„ ê²€ì¦ í…ŒìŠ¤íŠ¸")
    print("=" * 60)

    # 1) ì§€ìˆ˜ ìŠ¤ëƒ…ìƒ· í…ŒìŠ¤íŠ¸
    print("\n[1] ë¯¸êµ­ ì‹œì¥ ì§€ìˆ˜ ìŠ¤ëƒ…ìƒ· ìˆ˜ì§‘...")
    indices = fetch_index_snapshot()
    for name, data in indices.items():
        price = data.get("price", 0)
        chg = data.get("change_pct", 0)
        print(f"  {name}: {price:,.2f} ({chg:+.2f}%)")

    # 2) ìŠ¤ëƒ…ìƒ· ê¸°ë¡ í…ŒìŠ¤íŠ¸
    print("\n[2] ìŠ¤ëƒ…ìƒ· ê¸°ë¡ í…ŒìŠ¤íŠ¸...")
    snapshot = record_hourly_snapshot(
        urgency="MEDIUM",
        trend_narrative="ì „ìŸ ê´€ë ¨ ë‰´ìŠ¤ 3ê±´ ê°ì§€",
        urgent_items=[{"title": "ë¯¸-ì´ë€ ê¸´ì¥ ê³ ì¡°", "score": 8}],
    )
    print(f"  ê¸°ë¡ ì™„ë£Œ: {snapshot.timestamp}")

    # 3) ë¦¬í¬íŠ¸ ìƒì„± í…ŒìŠ¤íŠ¸
    print("\n[3] ê²€ì¦ ë¦¬í¬íŠ¸ ìƒì„±...")
    report = generate_validation_report()
    print(f"  ì¼ì¹˜ìœ¨: {report['match_rate_24h']:.0%}")
    print(f"  ê²°ë¡ : {report['conclusion']}")

    # 4) í…”ë ˆê·¸ë¨ í¬ë§·
    print("\n[4] í…”ë ˆê·¸ë¨ ë©”ì‹œì§€ ë¯¸ë¦¬ë³´ê¸°:")
    msg = format_validation_report_telegram(report)
    print(msg)

    print("\n" + "=" * 60)
    print("  âœ… news_market_validator.py í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    print("=" * 60)
