"""
extended_backtest.py â€” í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ Suite
================================================================================
ê¸°ì¡´ 2,000íšŒ íƒìƒ‰ â†’ 10,000íšŒ ì´ìƒ + ì¶”ê°€ ë¶„ì„ ëª¨ë“ˆ

ëª©ì°¨:
  1. í™•ì¥ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œì„œì¹˜ (10,000íšŒ)
  2. ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„
  3. ì§„ì… ì‹œê°„ëŒ€ ë¶„ì„ (ì›”~ê¸ˆ, ìš”ì¼ë³„)
  4. ì›Œí¬í¬ì›Œë“œ ê²€ì¦ (3-fold)
  5. ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ (1,000íšŒ shuffle)
  6. ì˜¤ë²„ë‚˜ì´íŠ¸ ì„ê³„ê°’ ìµœì í™”
  7. ë³µí•© ë§¤í¬ë¡œ í•„í„° ì¡°í•© íƒìƒ‰
  8. í†µí•© ê²°ê³¼ ë¦¬í¬íŠ¸
"""
import os, sys, logging, json, random
import numpy as np
import pandas as pd
from pathlib import Path
from datetime import datetime
from typing import List, Dict, Tuple, Optional
from dataclasses import dataclass, field
from scipy import stats

sys.path.insert(0, str(Path(__file__).parent.parent))

logging.basicConfig(
    level=logging.INFO,
    format="%(asctime)s [%(levelname)s] %(message)s",
    handlers=[
        logging.StreamHandler(),
        logging.FileHandler(
            f"analysis/results/ext_backtest_{datetime.now().strftime('%Y%m%d_%H%M%S')}.log"
        ),
    ],
)
logger = logging.getLogger("extended_backtest")

OUT_DIR = Path("analysis/results/extended")
OUT_DIR.mkdir(parents=True, exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 0. ì „ì—­ ê¸°ê°„ ì„¤ì •
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
FULL_START  = "20230901"
FULL_END    = "20260224"
TRAIN_START = "20230901"
TRAIN_END   = "20241231"   # ì•½ 16ê°œì›” (í•™ìŠµ)
TEST_START  = "20250101"
TEST_END    = "20260224"   # ì•½ 14ê°œì›” (ê²€ì¦)

# Walk-forward fold ì •ì˜
WF_FOLDS = [
    {"train_start": "20230901", "train_end": "20240630",
     "test_start":  "20240701", "test_end":  "20241231"},
    {"train_start": "20230901", "train_end": "20241231",
     "test_start":  "20250101", "test_end":  "20250630"},
    {"train_start": "20230901", "train_end": "20250630",
     "test_start":  "20250701", "test_end":  "20260224"},
]


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. í™•ì¥ íŒŒë¼ë¯¸í„° ê·¸ë¦¬ë“œ ì •ì˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

EXTENDED_PARAM_GRID = {
    # DC ê¸°ê°„: ê¸°ì¡´ 3ê°œ â†’ 7ê°œ
    "dc_period":       [10, 15, 20, 25, 30, 40, 60],
    # ê±°ë˜ëŸ‰ ë°°ìœ¨: ê¸°ì¡´ê³¼ ë™ì¼
    "vol_ratio_min":   [1.5, 2.0, 2.5, 3.0],
    # ADX: ì„¸ë¶„í™”
    "adx_min":         [15.0, 20.0, 25.0, 30.0, 35.0],
    # RSI ë²”ìœ„: ì„¸ë¶„í™”
    "rsi_min":         [30.0, 35.0, 40.0, 45.0, 50.0],
    "rsi_max":         [65.0, 70.0, 75.0, 80.0, 85.0],
    # ATR ë°°ìˆ˜: ì„¸ë¶„í™”
    "atr_stop_mult":   [1.0, 1.5, 2.0, 2.5, 3.0],
    # íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘: ì„¸ë¶„í™”
    "trail_stop_pct":  [0.02, 0.03, 0.04, 0.05, 0.07],
    # ì´ìµì‹¤í˜„: ì„¸ë¶„í™”
    "take_profit":     [0.07, 0.08, 0.10, 0.12, 0.15, 0.20],
    # íƒ€ì„ìŠ¤íƒ‘: ì„¸ë¶„í™”
    "time_stop_days":  [3, 5, 7, 10, 15, 20],
    # ì˜¤ë²„ë‚˜ì´íŠ¸ ìµœì†Œ ìˆ˜ìµë¥ 
    "overnight_min":   [0.05, 0.07, 0.10, 0.12],
}

@dataclass
class ExtParams:
    dc_period:       int   = 20
    vol_ratio_min:   float = 2.0
    adx_min:         float = 25.0
    rsi_min:         float = 40.0
    rsi_max:         float = 75.0
    atr_stop_mult:   float = 2.0
    trail_stop_pct:  float = 0.03
    take_profit:     float = 0.10
    time_stop_days:  int   = 7
    overnight_min:   float = 0.07
    max_positions:   int   = 5
    position_size:   float = 0.20

    def key(self) -> str:
        return (f"dc{self.dc_period}_v{self.vol_ratio_min}"
                f"_adx{self.adx_min}_atr{self.atr_stop_mult}"
                f"_tr{self.trail_stop_pct}_tp{self.take_profit}"
                f"_ts{self.time_stop_days}")


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ì‹ í˜¸ ìƒì„± (ê¸°ì¡´ generate_signals í™•ì¥íŒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_signals_ext(df: pd.DataFrame, params: ExtParams) -> pd.DataFrame:
    """í™•ì¥ ì‹ í˜¸ ìƒì„± â€” ê¸°ì¡´ ë¡œì§ + ìš”ì¼ ì»¬ëŸ¼ ì¶”ê°€"""
    dc_col = f"dc_high{params.dc_period}"
    df = df.copy()

    if dc_col not in df.columns:
        df[dc_col] = df.groupby("ticker")["high"].transform(
            lambda x: x.shift(1).rolling(params.dc_period).max()
        )

    # ê¸°ë³¸ ì‹ í˜¸
    df["sig_dc"]  = df["close"] > df[dc_col]
    df["sig_vol"] = df["vol_ratio"] >= params.vol_ratio_min
    df["sig_adx"] = df["adx14"] >= params.adx_min
    df["sig_rsi"] = (df["rsi14"] >= params.rsi_min) & (df["rsi14"] <= params.rsi_max)
    df["sig_ma"]  = df["close"] > df["ma60"]

    df["entry_signal"] = (
        df["sig_dc"] & df["sig_vol"] & df["sig_adx"] & df["sig_rsi"] & df["sig_ma"]
    )

    # ìš”ì¼ ì¶”ê°€ (ë¶„ì„ìš©)
    if "date" in df.columns:
        try:
            df["weekday"] = pd.to_datetime(df["date"], format="%Y%m%d").dt.dayofweek
            df["month"]   = pd.to_datetime(df["date"], format="%Y%m%d").dt.month
        except Exception:
            pass

    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„ (í™•ì¥íŒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

@dataclass
class Position:
    ticker:      str
    entry_date:  str
    entry_price: float
    stop_price:  float
    peak_price:  float
    allocated:   float = 0.0
    hold_days:   int   = 0
    weekday:     int   = -1   # ì§„ì… ìš”ì¼ (0=ì›”, 4=ê¸ˆ)
    month:       int   = -1

@dataclass
class TradeRecord:
    ticker:       str
    entry_date:   str
    exit_date:    str
    entry_price:  float
    exit_price:   float
    ret:          float
    pnl:          float
    hold_days:    int
    exit_reason:  str
    weekday:      int = -1
    month:        int = -1


def run_backtest_ext(df: pd.DataFrame, params: ExtParams,
                     start_date: str = TRAIN_START,
                     end_date:   str = TRAIN_END,
                     initial_capital: float = 100_000_000) -> Dict:
    """
    í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ ì—”ì§„
    ë°˜í™˜: {sharpe, total_return, mdd, win_rate, trade_count, avg_hold_days,
            profit_factor, trades, equity_curve}
    """
    result = {
        "sharpe": 0.0, "total_return": 0.0, "mdd": 0.0,
        "win_rate": 0.0, "trade_count": 0, "avg_hold_days": 0.0,
        "profit_factor": 0.0, "trades": [], "equity_curve": [],
        "params": params,
    }

    data = df[(df["date"] >= start_date) & (df["date"] <= end_date)].copy()
    if data.empty:
        return result

    needed = ["close", "atr14", "vol_ratio", "entry_signal", "weekday", "month"]
    needed = [c for c in needed if c in data.columns]

    data_dict: Dict[str, Dict] = {}
    for date, grp in data.groupby("date"):
        data_dict[date] = grp.set_index("ticker")[needed].to_dict("index")

    dates = sorted(data_dict.keys())
    positions: Dict[str, Position] = {}
    cash = initial_capital
    equity_curve = []
    trades: List[TradeRecord] = []

    for date in dates:
        day_dict = data_dict.get(date, {})

        # â”€â”€ 1. ì²­ì‚° ì²´í¬ â”€â”€
        to_close = []
        for ticker, pos in positions.items():
            row = day_dict.get(ticker)
            pos.hold_days += 1
            if row is None:
                continue

            price = float(row["close"])
            pos.peak_price = max(pos.peak_price, price)

            trail_stop     = pos.peak_price * (1 - params.trail_stop_pct)
            effective_stop = max(pos.stop_price, trail_stop)

            exit_reason = None
            exit_price  = price
            if price <= effective_stop:
                exit_reason = "stop"
                exit_price  = max(effective_stop, price * 0.98)
            elif (price / pos.entry_price - 1) >= params.take_profit:
                exit_reason = "take_profit"
            elif pos.hold_days >= params.time_stop_days:
                exit_reason = "time_stop"

            if exit_reason:
                ret        = exit_price / pos.entry_price - 1
                exit_value = pos.allocated * (1 + ret)
                pnl        = exit_value - pos.allocated
                cash      += exit_value
                trades.append(TradeRecord(
                    ticker=ticker, entry_date=pos.entry_date, exit_date=date,
                    entry_price=pos.entry_price, exit_price=exit_price,
                    ret=ret, pnl=pnl, hold_days=pos.hold_days,
                    exit_reason=exit_reason,
                    weekday=pos.weekday, month=pos.month,
                ))
                to_close.append(ticker)

        for t in to_close:
            del positions[t]

        # â”€â”€ 2. ì§„ì… â”€â”€
        if len(positions) < params.max_positions:
            sigs = [
                (t, float(r.get("vol_ratio", 0)))
                for t, r in day_dict.items()
                if r.get("entry_signal") == True and t not in positions
            ]
            sigs.sort(key=lambda x: x[1], reverse=True)

            slots = params.max_positions - len(positions)
            for ticker, _ in sigs[:slots]:
                row   = day_dict[ticker]
                price = float(row["close"])

                pos_val = sum(
                    p.allocated * (float(day_dict[t]["close"]) / p.entry_price
                                   if t in day_dict else 1.0)
                    for t, p in positions.items()
                )
                total_eq = cash + pos_val
                alloc    = total_eq * params.position_size
                if alloc > cash:
                    continue

                atr  = float(row.get("atr14", price * 0.02))
                stop = price - params.atr_stop_mult * atr
                cash -= alloc
                positions[ticker] = Position(
                    ticker=ticker, entry_date=date, entry_price=price,
                    stop_price=stop, peak_price=price, allocated=alloc,
                    weekday=int(row.get("weekday", -1)),
                    month=int(row.get("month", -1)),
                )

        # â”€â”€ 3. ìë³¸ ìŠ¤ëƒ…ìƒ· â”€â”€
        pos_value = 0.0
        for ticker, pos in positions.items():
            row = day_dict.get(ticker)
            cur_price = float(row["close"]) if row else pos.entry_price
            pos_value += pos.allocated * (cur_price / pos.entry_price)
        equity_curve.append({"date": date, "equity": cash + pos_value})

    # â”€â”€ ì„±ê³¼ ê³„ì‚° â”€â”€
    if len(trades) < 10:
        return result

    eq  = pd.DataFrame(equity_curve).set_index("date")["equity"]
    ret = eq.pct_change().dropna()
    rets = [t.ret for t in trades]
    wins = [r for r in rets if r > 0]
    loss = [r for r in rets if r <= 0]

    result.update({
        "total_return":  float(eq.iloc[-1] / eq.iloc[0] - 1),
        "mdd":           float(_calc_mdd(eq)),
        "sharpe":        float(ret.mean() / (ret.std() + 1e-9) * np.sqrt(252)),
        "win_rate":      len(wins) / len(rets),
        "trade_count":   len(rets),
        "avg_hold_days": np.mean([t.hold_days for t in trades]),
        "profit_factor": sum(wins) / (abs(sum(loss)) + 1e-9),
        "trades":        trades,
        "equity_curve":  equity_curve,
    })
    return result


def _calc_mdd(equity: pd.Series) -> float:
    peak = equity.cummax()
    dd   = (equity - peak) / peak
    return float(dd.min())


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. í™•ì¥ íŒŒë¼ë¯¸í„° ìµœì í™” (10,000íšŒ)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_extended_optimization(df: pd.DataFrame,
                               n_trials: int = 10000,
                               top_k: int = 50) -> List[Dict]:
    """
    10,000íšŒ ëœë¤ íƒìƒ‰ â†’ ìƒìœ„ top_k ë°˜í™˜
    DC ê¸°ê°„ë³„ë¡œ ì‹ í˜¸ë¥¼ ë¯¸ë¦¬ ê³„ì‚°í•˜ì—¬ ì†ë„ ìµœì í™”
    """
    logger.info(f"[ìµœì í™”] {n_trials:,}íšŒ íŒŒë¼ë¯¸í„° íƒìƒ‰ ì‹œì‘...")

    # DC ê¸°ê°„ë³„ ì‹ í˜¸ ì‚¬ì „ ê³„ì‚°
    logger.info("DC ê¸°ê°„ë³„ ì‹ í˜¸ ì‚¬ì „ ê³„ì‚° ì¤‘...")
    sig_cache: Dict[int, pd.DataFrame] = {}
    for dc in EXTENDED_PARAM_GRID["dc_period"]:
        p = ExtParams(dc_period=dc)
        sig_cache[dc] = generate_signals_ext(df.copy(), p)
        logger.info(f"  DC={dc} ì™„ë£Œ, ì‹ í˜¸ìˆ˜={sig_cache[dc]['entry_signal'].sum():,}")

    results = []
    for i in range(n_trials):
        if i % 500 == 0:
            logger.info(f"  {i}/{n_trials} ì§„í–‰ ì¤‘... (ìœ íš¨ê²°ê³¼: {len(results)}ê°œ)")

        # ëœë¤ íŒŒë¼ë¯¸í„° ìƒ˜í”Œë§
        params = ExtParams(
            dc_period      = random.choice(EXTENDED_PARAM_GRID["dc_period"]),
            vol_ratio_min  = random.choice(EXTENDED_PARAM_GRID["vol_ratio_min"]),
            adx_min        = random.choice(EXTENDED_PARAM_GRID["adx_min"]),
            rsi_min        = random.choice(EXTENDED_PARAM_GRID["rsi_min"]),
            rsi_max        = random.choice(EXTENDED_PARAM_GRID["rsi_max"]),
            atr_stop_mult  = random.choice(EXTENDED_PARAM_GRID["atr_stop_mult"]),
            trail_stop_pct = random.choice(EXTENDED_PARAM_GRID["trail_stop_pct"]),
            take_profit    = random.choice(EXTENDED_PARAM_GRID["take_profit"]),
            time_stop_days = random.choice(EXTENDED_PARAM_GRID["time_stop_days"]),
            overnight_min  = random.choice(EXTENDED_PARAM_GRID["overnight_min"]),
        )

        sig_df = sig_cache[params.dc_period]
        r = run_backtest_ext(sig_df, params, TRAIN_START, TRAIN_END)
        if r["trade_count"] >= 30:
            results.append(r)

    results.sort(key=lambda x: x["sharpe"], reverse=True)
    top = results[:top_k]

    # CSV ì €ì¥
    rows = []
    for r in top:
        p = r["params"]
        rows.append({
            "dc_period":       p.dc_period,
            "vol_ratio_min":   p.vol_ratio_min,
            "adx_min":         p.adx_min,
            "rsi_min":         p.rsi_min,
            "rsi_max":         p.rsi_max,
            "atr_stop_mult":   p.atr_stop_mult,
            "trail_stop_pct":  p.trail_stop_pct,
            "take_profit":     p.take_profit,
            "time_stop_days":  p.time_stop_days,
            "overnight_min":   p.overnight_min,
            "total_return%":   round(r["total_return"] * 100, 2),
            "sharpe":          round(r["sharpe"], 3),
            "mdd%":            round(r["mdd"] * 100, 2),
            "win_rate%":       round(r["win_rate"] * 100, 1),
            "trade_count":     r["trade_count"],
            "avg_hold_days":   round(r["avg_hold_days"], 1),
            "profit_factor":   round(r["profit_factor"], 3),
        })

    df_out = pd.DataFrame(rows)
    df_out.to_csv(OUT_DIR / "ext_top_params.csv", index=False)
    logger.info(f"[ìµœì í™”] ì™„ë£Œ: ìœ íš¨ê²°ê³¼ {len(results)}ê°œ, ìƒìœ„ {len(top)}ê°œ ì €ì¥")

    # íŒŒë¼ë¯¸í„° ë¶„í¬ ë¶„ì„ (ìˆ˜ë ´ í™•ì¸)
    _analyze_param_distribution(df_out, top_k)
    return top


def _analyze_param_distribution(df: pd.DataFrame, top_k: int):
    """ìƒìœ„ ê²°ê³¼ë“¤ì˜ íŒŒë¼ë¯¸í„° ë¶„í¬ ë¶„ì„ â€” ìˆ˜ë ´ ì—¬ë¶€ í™•ì¸"""
    logger.info("\n[íŒŒë¼ë¯¸í„° ë¶„í¬ ë¶„ì„] ìƒìœ„ ê²°ê³¼ ì§‘ì¤‘ë„:")
    cols = ["dc_period", "vol_ratio_min", "adx_min", "atr_stop_mult",
            "trail_stop_pct", "take_profit", "time_stop_days"]
    rows = []
    for col in cols:
        vc = df[col].value_counts(normalize=True)
        top_val = vc.index[0]
        top_pct = vc.iloc[0] * 100
        rows.append({"íŒŒë¼ë¯¸í„°": col, "ìµœë¹ˆê°’": top_val, "ì§‘ì¤‘ë„%": round(top_pct, 1)})
        logger.info(f"  {col}: ìµœë¹ˆê°’={top_val}, ì§‘ì¤‘ë„={top_pct:.0f}%")

    dist_df = pd.DataFrame(rows)
    dist_df.to_csv(OUT_DIR / "param_distribution.csv", index=False)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. ì›Œí¬í¬ì›Œë“œ ê²€ì¦ (3-fold)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_walk_forward(df: pd.DataFrame, top_params: List[Dict],
                     top_n: int = 10) -> pd.DataFrame:
    """
    3-fold Walk-Forward ê²€ì¦
    ê° foldì—ì„œ ìƒìœ„ íŒŒë¼ë¯¸í„°ë¥¼ í•™ìŠµ ê¸°ê°„ìœ¼ë¡œ ì¬íƒìƒ‰ í›„ ê²€ì¦ ê¸°ê°„ ì ìš©
    """
    logger.info("\n[ì›Œí¬í¬ì›Œë“œ] 3-fold ê²€ì¦ ì‹œì‘...")

    # DC ê¸°ê°„ë³„ ì‹ í˜¸ ìºì‹œ
    sig_cache: Dict[int, pd.DataFrame] = {}
    for dc in EXTENDED_PARAM_GRID["dc_period"]:
        p = ExtParams(dc_period=dc)
        sig_cache[dc] = generate_signals_ext(df.copy(), p)

    wf_results = []

    for fold_i, fold in enumerate(WF_FOLDS):
        logger.info(f"\n  Fold {fold_i+1}/3: "
                    f"í•™ìŠµ={fold['train_start']}~{fold['train_end']}, "
                    f"ê²€ì¦={fold['test_start']}~{fold['test_end']}")

        # ì´ foldì˜ í•™ìŠµê¸°ê°„ì—ì„œ íŒŒë¼ë¯¸í„° ìµœì í™” (2,000íšŒ ë¹ ë¥¸ íƒìƒ‰)
        fold_results = []
        for _ in range(2000):
            params = ExtParams(
                dc_period      = random.choice(EXTENDED_PARAM_GRID["dc_period"]),
                vol_ratio_min  = random.choice(EXTENDED_PARAM_GRID["vol_ratio_min"]),
                adx_min        = random.choice(EXTENDED_PARAM_GRID["adx_min"]),
                rsi_min        = random.choice(EXTENDED_PARAM_GRID["rsi_min"]),
                rsi_max        = random.choice(EXTENDED_PARAM_GRID["rsi_max"]),
                atr_stop_mult  = random.choice(EXTENDED_PARAM_GRID["atr_stop_mult"]),
                trail_stop_pct = random.choice(EXTENDED_PARAM_GRID["trail_stop_pct"]),
                take_profit    = random.choice(EXTENDED_PARAM_GRID["take_profit"]),
                time_stop_days = random.choice(EXTENDED_PARAM_GRID["time_stop_days"]),
            )
            sig_df = sig_cache[params.dc_period]
            r = run_backtest_ext(sig_df, params,
                                  fold["train_start"], fold["train_end"])
            if r["trade_count"] >= 20:
                fold_results.append((r["sharpe"], params))

        if not fold_results:
            logger.warning(f"  Fold {fold_i+1}: ìœ íš¨ ê²°ê³¼ ì—†ìŒ")
            continue

        fold_results.sort(key=lambda x: x[0], reverse=True)
        best_train_sharpe, best_params = fold_results[0]

        # ê²€ì¦ ê¸°ê°„ í…ŒìŠ¤íŠ¸
        sig_df = sig_cache[best_params.dc_period]
        test_r = run_backtest_ext(sig_df, best_params,
                                   fold["test_start"], fold["test_end"])

        wf_results.append({
            "fold":              fold_i + 1,
            "train_start":       fold["train_start"],
            "train_end":         fold["train_end"],
            "test_start":        fold["test_start"],
            "test_end":          fold["test_end"],
            "train_sharpe":      round(best_train_sharpe, 3),
            "test_sharpe":       round(test_r["sharpe"], 3),
            "test_return%":      round(test_r["total_return"] * 100, 2),
            "test_mdd%":         round(test_r["mdd"] * 100, 2),
            "test_win_rate%":    round(test_r["win_rate"] * 100, 1),
            "test_trades":       test_r["trade_count"],
            "dc_period":         best_params.dc_period,
            "trail_stop_pct":    best_params.trail_stop_pct,
            "take_profit":       best_params.take_profit,
            "time_stop_days":    best_params.time_stop_days,
            "overfitting_ratio": round(test_r["sharpe"] / (best_train_sharpe + 1e-9), 3),
        })

        logger.info(f"  Fold {fold_i+1}: "
                    f"í•™ìŠµ Sharpe={best_train_sharpe:.2f}, "
                    f"ê²€ì¦ Sharpe={test_r['sharpe']:.2f}, "
                    f"ê²€ì¦ ìˆ˜ìµë¥ ={test_r['total_return']*100:.1f}%, "
                    f"ê³¼ì í•© ë¹„ìœ¨={test_r['sharpe']/(best_train_sharpe+1e-9):.2f}")

    wf_df = pd.DataFrame(wf_results)
    wf_df.to_csv(OUT_DIR / "walk_forward.csv", index=False)
    logger.info(f"\n[ì›Œí¬í¬ì›Œë“œ] ì™„ë£Œ. í‰ê·  ê³¼ì í•© ë¹„ìœ¨: "
                f"{wf_df['overfitting_ratio'].mean():.2f}")
    return wf_df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_monte_carlo(best_result: Dict,
                    n_simulations: int = 2000,
                    confidence: float = 0.95) -> Dict:
    """
    ê±°ë˜ ìˆœì„œ ì…”í”Œ ê¸°ë°˜ ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜
    - ì‹¤ì œ ê±°ë˜ ìˆ˜ìµë¥  ë¦¬ìŠ¤íŠ¸ë¥¼ ë¬´ì‘ìœ„ ì¬ë°°ì—´
    - ê° ì‹œë®¬ë ˆì´ì…˜ì—ì„œ Sharpe, MDD, ì´ìˆ˜ìµë¥  ê³„ì‚°
    - 95% ì‹ ë¢°êµ¬ê°„ ì¶”ì •
    """
    logger.info(f"\n[ëª¬í…Œì¹´ë¥¼ë¡œ] {n_simulations:,}íšŒ ì‹œë®¬ë ˆì´ì…˜ ì‹œì‘...")

    trades = best_result.get("trades", [])
    if len(trades) < 30:
        logger.warning("ê±°ë˜ ìˆ˜ ë¶€ì¡± (<30) â€” ëª¬í…Œì¹´ë¥¼ë¡œ ìŠ¤í‚µ")
        return {}

    rets = [t.ret for t in trades]
    initial_capital = 100_000_000
    position_size   = best_result["params"].position_size
    max_pos         = best_result["params"].max_positions

    mc_sharpes = []
    mc_returns = []
    mc_mdds    = []

    for sim in range(n_simulations):
        shuffled = rets.copy()
        random.shuffle(shuffled)

        # í¬íŠ¸í´ë¦¬ì˜¤ ìˆ˜ìµë¥  ì‹œë®¬ë ˆì´ì…˜ (ë…ë¦½ ê±°ë˜ ê°€ì •)
        # ë§¤ ê±°ë˜ë¥¼ ì‹œê°„ ìˆœìœ¼ë¡œ ì ìš©, position_size ë¹„ìœ¨ë¡œ ëˆ„ì 
        capital = 1.0
        equity  = [1.0]

        # max_pos ê°œ ë™ì‹œ ë³´ìœ  ê°€ì •ìœ¼ë¡œ ìŠ¬ë¼ì´ë”© ìœˆë„ìš°
        batch_size = max_pos
        for i in range(0, len(shuffled), batch_size):
            batch = shuffled[i:i+batch_size]
            batch_ret = np.mean(batch) * position_size * len(batch)
            capital *= (1 + batch_ret)
            equity.append(capital)

        eq = pd.Series(equity)
        daily_ret = eq.pct_change().dropna()

        mc_sharpes.append(float(daily_ret.mean() / (daily_ret.std() + 1e-9) * np.sqrt(252 / batch_size)))
        mc_returns.append(float(eq.iloc[-1] - 1))
        mc_mdds.append(float(_calc_mdd(eq)))

    mc_sharpes = np.array(mc_sharpes)
    mc_returns = np.array(mc_returns)
    mc_mdds    = np.array(mc_mdds)

    alpha = 1 - confidence
    result = {
        "n_simulations":   n_simulations,
        "n_trades":        len(rets),
        "actual_sharpe":   round(best_result["sharpe"], 3),
        "actual_return":   round(best_result["total_return"] * 100, 2),
        "actual_mdd":      round(best_result["mdd"] * 100, 2),
        # Sharpe
        "sharpe_mean":     round(float(mc_sharpes.mean()), 3),
        "sharpe_std":      round(float(mc_sharpes.std()), 3),
        f"sharpe_p{int(alpha*50)}":  round(float(np.percentile(mc_sharpes, alpha/2 * 100)), 3),
        f"sharpe_p{int((1-alpha/2)*100)}": round(float(np.percentile(mc_sharpes, (1-alpha/2)*100)), 3),
        "sharpe_positive_prob": round(float((mc_sharpes > 0).mean() * 100), 1),
        # Return
        "return_mean%":    round(float(mc_returns.mean() * 100), 2),
        "return_p5%":      round(float(np.percentile(mc_returns, 5) * 100), 2),
        "return_p95%":     round(float(np.percentile(mc_returns, 95) * 100), 2),
        # MDD
        "mdd_mean%":       round(float(mc_mdds.mean() * 100), 2),
        "mdd_p95%":        round(float(np.percentile(mc_mdds, 95) * 100), 2),
    }

    pd.DataFrame([result]).to_csv(OUT_DIR / "monte_carlo.csv", index=False)
    logger.info(f"[ëª¬í…Œì¹´ë¥¼ë¡œ] Sharpe ë¶„í¬: {result['sharpe_mean']:.2f} Â± {result['sharpe_std']:.2f}")
    logger.info(f"  ì–‘ì˜ Sharpe í™•ë¥ : {result['sharpe_positive_prob']}%")
    logger.info(f"  ìˆ˜ìµë¥  95CI: [{result['return_p5%']}%, {result['return_p95%']}%]")
    logger.info(f"  MDD 95ë°±ë¶„ìœ„: {result['mdd_p95%']}%")
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

# KOSPI/KOSDAQ ì„¹í„° ë§¤í•‘ (ì£¼ìš” ì—…ì¢… ëŒ€í‘œ ì¢…ëª© ì½”ë“œ)
SECTOR_MAP = {
    "ë°˜ë„ì²´":    ["005930", "000660", "091160", "229200", "042700", "688700"],
    "2ì°¨ì „ì§€":   ["006400", "373220", "051910", "096770", "000270", "012330"],
    "ë°”ì´ì˜¤/ì œì•½": ["207940", "068270", "326030", "086900", "145020", "214450"],
    "ê¸ˆìœµ":      ["105560", "055550", "086790", "316140", "175330", "032830"],
    "ìë™ì°¨":    ["005380", "012330", "000270", "204320", "011210", "003620"],
    "ì—”í„°/ë¯¸ë””ì–´": ["041510", "035900", "352820", "122870", "251270"],
    "ì¡°ì„ /ë°©ì‚°": ["010140", "042660", "006360", "047050", "272210"],
    "ì†Œë¹„ì¬/ìœ í†µ": ["069960", "009150", "028260", "139480", "004170"],
}


def analyze_sector_performance(df: pd.DataFrame, best_params: ExtParams) -> pd.DataFrame:
    """ì„¹í„°ë³„ ë°±í…ŒìŠ¤íŠ¸ ì„±ê³¼ ë¶„ì„"""
    logger.info("\n[ì„¹í„° ë¶„ì„] ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„ ì¤‘...")

    sig_df = generate_signals_ext(df.copy(), best_params)

    rows = []

    # ì „ì²´ ì„±ê³¼ (ë² ì´ìŠ¤ë¼ì¸)
    base_r = run_backtest_ext(sig_df, best_params, FULL_START, FULL_END)
    rows.append({
        "sector": "ì „ì²´",
        "tickers": len(df["ticker"].unique()),
        "total_return%": round(base_r["total_return"] * 100, 2),
        "sharpe": round(base_r["sharpe"], 3),
        "mdd%": round(base_r["mdd"] * 100, 2),
        "win_rate%": round(base_r["win_rate"] * 100, 1),
        "trade_count": base_r["trade_count"],
        "avg_hold_days": round(base_r["avg_hold_days"], 1),
    })

    # ì„¹í„°ë³„ í•„í„°ë§ í›„ ì„±ê³¼
    all_tickers = set(df["ticker"].unique())
    for sector, tickers in SECTOR_MAP.items():
        # ì´ ì„¹í„° ì¢…ëª©ë§Œ í¬í•¨ëœ ë°ì´í„°í”„ë ˆì„
        sector_tickers = [t for t in tickers if t in all_tickers]
        if len(sector_tickers) < 2:
            logger.debug(f"  {sector}: ë°ì´í„° ì—†ìŒ (ë³´ìœ :{sector_tickers})")
            continue

        sec_df = sig_df[sig_df["ticker"].isin(sector_tickers)].copy()
        if len(sec_df) < 100:
            continue

        r = run_backtest_ext(sec_df, best_params, FULL_START, FULL_END)
        if r["trade_count"] < 5:
            continue

        rows.append({
            "sector": sector,
            "tickers": len(sector_tickers),
            "total_return%": round(r["total_return"] * 100, 2),
            "sharpe": round(r["sharpe"], 3),
            "mdd%": round(r["mdd"] * 100, 2),
            "win_rate%": round(r["win_rate"] * 100, 1),
            "trade_count": r["trade_count"],
            "avg_hold_days": round(r["avg_hold_days"], 1),
        })
        logger.info(f"  {sector}: ìˆ˜ìµ={r['total_return']*100:.1f}%, "
                    f"Sharpe={r['sharpe']:.2f}, ê±°ë˜={r['trade_count']}")

    result = pd.DataFrame(rows)
    result.to_csv(OUT_DIR / "sector_performance.csv", index=False)
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 8. ìš”ì¼ë³„ / ì›”ë³„ ì„±ê³¼ ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_temporal_patterns(trades: List[TradeRecord]) -> Dict:
    """ìš”ì¼ë³„, ì›”ë³„ ì§„ì… ì„±ê³¼ ë¶„ì„"""
    logger.info("\n[ì‹œê°„ëŒ€ ë¶„ì„] ìš”ì¼/ì›”ë³„ íŒ¨í„´ ë¶„ì„...")

    if not trades:
        return {}

    df = pd.DataFrame([{
        "weekday":    t.weekday,
        "month":      t.month,
        "ret":        t.ret,
        "hold_days":  t.hold_days,
        "exit_reason": t.exit_reason,
    } for t in trades])

    results = {}

    # ìš”ì¼ë³„ ë¶„ì„
    weekday_names = {0: "ì›”", 1: "í™”", 2: "ìˆ˜", 3: "ëª©", 4: "ê¸ˆ"}
    weekday_rows = []
    for wd, name in weekday_names.items():
        sub = df[df["weekday"] == wd]["ret"]
        if len(sub) < 5:
            continue
        weekday_rows.append({
            "ìš”ì¼": name, "n": len(sub),
            "mean_ret%": round(sub.mean() * 100, 2),
            "win_rate%": round((sub > 0).mean() * 100, 1),
            "std%":      round(sub.std() * 100, 2),
        })

    wday_df = pd.DataFrame(weekday_rows)
    results["weekday"] = wday_df
    if not wday_df.empty:
        logger.info(f"\nìš”ì¼ë³„ ì§„ì… ìˆ˜ìµë¥ :\n{wday_df.to_string(index=False)}")

    # ì›”ë³„ ë¶„ì„
    month_rows = []
    for m in range(1, 13):
        sub = df[df["month"] == m]["ret"]
        if len(sub) < 3:
            continue
        month_rows.append({
            "ì›”": m, "n": len(sub),
            "mean_ret%": round(sub.mean() * 100, 2),
            "win_rate%": round((sub > 0).mean() * 100, 1),
        })

    month_df = pd.DataFrame(month_rows)
    results["month"] = month_df
    if not month_df.empty:
        logger.info(f"\nì›”ë³„ ì§„ì… ìˆ˜ìµë¥ :\n{month_df.to_string(index=False)}")

    # ì²­ì‚° ì´ìœ ë³„ í†µê³„
    reason_rows = []
    for reason in df["exit_reason"].unique():
        sub = df[df["exit_reason"] == reason]["ret"]
        reason_rows.append({
            "ì²­ì‚°ì´ìœ ": reason, "n": len(sub),
            "mean_ret%": round(sub.mean() * 100, 2),
            "win_rate%": round((sub > 0).mean() * 100, 1),
            "avg_hold":  round(df[df["exit_reason"] == reason]["hold_days"].mean(), 1),
        })

    reason_df = pd.DataFrame(reason_rows)
    results["exit_reason"] = reason_df
    logger.info(f"\nì²­ì‚°ì´ìœ ë³„ í†µê³„:\n{reason_df.to_string(index=False)}")

    # CSV ì €ì¥
    wday_df.to_csv(OUT_DIR / "weekday_analysis.csv", index=False)
    month_df.to_csv(OUT_DIR / "month_analysis.csv", index=False)
    reason_df.to_csv(OUT_DIR / "exit_reason_analysis.csv", index=False)

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 9. ì˜¤ë²„ë‚˜ì´íŠ¸ ì„ê³„ê°’ ìµœì í™”
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def optimize_overnight_threshold(df: pd.DataFrame,
                                  base_params: ExtParams) -> pd.DataFrame:
    """
    ì˜¤ë²„ë‚˜ì´íŠ¸ ë³´ìœ  ìµœì†Œ ìˆ˜ìµë¥  ì„ê³„ê°’ ìµœì í™”
    í˜„ì¬: 7% ì´ìƒ ìˆ˜ìµ ì‹œ ì˜¤ë²„ë‚˜ì´íŠ¸ í—ˆìš©
    í…ŒìŠ¤íŠ¸: 3%, 5%, 7%, 10%, 12%, 15%
    """
    logger.info("\n[ì˜¤ë²„ë‚˜ì´íŠ¸] ì„ê³„ê°’ ìµœì í™”...")

    thresholds = [0.03, 0.05, 0.07, 0.10, 0.12, 0.15]
    rows = []

    sig_df = generate_signals_ext(df.copy(), base_params)

    for thr in thresholds:
        p = ExtParams(
            dc_period      = base_params.dc_period,
            vol_ratio_min  = base_params.vol_ratio_min,
            adx_min        = base_params.adx_min,
            rsi_min        = base_params.rsi_min,
            rsi_max        = base_params.rsi_max,
            atr_stop_mult  = base_params.atr_stop_mult,
            trail_stop_pct = base_params.trail_stop_pct,
            take_profit    = base_params.take_profit,
            time_stop_days = base_params.time_stop_days,
            overnight_min  = thr,
        )
        r = run_backtest_ext(sig_df, p, FULL_START, FULL_END)
        rows.append({
            "overnight_min%": round(thr * 100, 0),
            "total_return%":  round(r["total_return"] * 100, 2),
            "sharpe":         round(r["sharpe"], 3),
            "mdd%":           round(r["mdd"] * 100, 2),
            "win_rate%":      round(r["win_rate"] * 100, 1),
            "trade_count":    r["trade_count"],
        })
        logger.info(f"  ì˜¤ë²„ë‚˜ì´íŠ¸>{thr*100:.0f}%: "
                    f"ìˆ˜ìµ={r['total_return']*100:.1f}%, Sharpe={r['sharpe']:.2f}")

    result = pd.DataFrame(rows)
    result.to_csv(OUT_DIR / "overnight_threshold.csv", index=False)
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 10. ë³µí•© ë§¤í¬ë¡œ í•„í„° ì¡°í•© íƒìƒ‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_combined_macro_filters(daily_df: pd.DataFrame,
                                    macro_df: pd.DataFrame,
                                    base_params: ExtParams) -> pd.DataFrame:
    """
    ë³µí•© ë§¤í¬ë¡œ í•„í„° ì¡°í•© â†’ ìˆ˜ìµë¥  ê°œì„  ì—¬ë¶€ ê²€ì¦
    ê¸°ì¡´ ë‹¨ì¼ í•„í„° â†’ 2ì¤‘, 3ì¤‘ ì¡°í•©ìœ¼ë¡œ í™•ì¥
    """
    logger.info("\n[ë³µí•© ë§¤í¬ë¡œ í•„í„°] ì¡°í•© íƒìƒ‰...")

    sig_df = generate_signals_ext(daily_df.copy(), base_params)

    # ë§¤í¬ë¡œ ë°ì´í„° ë‚ ì§œ í¬ë§· ë§ì¶¤
    macro = macro_df.copy()
    if "date" in macro.columns:
        macro["date"] = macro["date"].astype(str).str.replace("-", "")

    # ì¼ë´‰ ë°ì´í„°ì™€ ë§¤í¬ë¡œ ë³‘í•©
    merged = sig_df.merge(macro, on="date", how="left")
    sig_rows = merged[merged["entry_signal"] == True].copy()

    if sig_rows.empty:
        logger.warning("ì‹ í˜¸ ì—†ìŒ")
        return pd.DataFrame()

    fwd_col = "fwd_ret5"
    if fwd_col not in sig_rows.columns:
        logger.warning("fwd_ret5 ì»¬ëŸ¼ ì—†ìŒ")
        return pd.DataFrame()

    base_ret = sig_rows[fwd_col].dropna().mean() * 100
    base_n   = len(sig_rows[fwd_col].dropna())
    logger.info(f"  ë² ì´ìŠ¤ë¼ì¸: {base_ret:.2f}%, N={base_n}")

    # ë‹¨ì¼ í•„í„°
    single_filters = {}
    if "yf_VIX" in sig_rows.columns or "VIX" in sig_rows.columns:
        vix = sig_rows.get("VIX", sig_rows.get("yf_VIX", None))
        if vix is not None:
            for v in [15, 18, 20, 22, 25]:
                single_filters[f"VIX<{v}"] = vix < v
    if "kospi_above_ma20" in sig_rows.columns:
        single_filters["KOSPI>MA20"] = sig_rows["kospi_above_ma20"] == 1
    if "dollar_strong" in sig_rows.columns:
        single_filters["ë‹¬ëŸ¬ì•½ì„¸"] = sig_rows["dollar_strong"] == 0
    if "regime" in sig_rows.columns:
        single_filters["RiskON"]   = sig_rows["regime"] == "risk_on"
        single_filters["Neutral+"] = sig_rows["regime"].isin(["risk_on", "neutral"])
    if "kospi_ret5d" in sig_rows.columns:
        for v in [-0.02, 0, 0.01, 0.02, 0.03]:
            single_filters[f"KOSPI5d>{v*100:.0f}%"] = sig_rows["kospi_ret5d"] > v

    # ë³µí•© í•„í„° (2ì¤‘ AND)
    filter_names = list(single_filters.keys())
    combo_filters = {}
    for i in range(len(filter_names)):
        for j in range(i+1, len(filter_names)):
            n1, n2 = filter_names[i], filter_names[j]
            combo_filters[f"{n1} & {n2}"] = (
                single_filters[n1] & single_filters[n2]
            )

    all_filters = {**single_filters, **combo_filters}

    rows = []
    for fname, mask in all_filters.items():
        try:
            filtered = sig_rows[mask][fwd_col].dropna()
            if len(filtered) < 15:
                continue
            t_stat, p_val = stats.ttest_ind(
                filtered, sig_rows[fwd_col].dropna(), equal_var=False
            )
            rows.append({
                "filter":      fname,
                "n":           len(filtered),
                "coverage%":   round(len(filtered) / base_n * 100, 1),
                "mean_ret%":   round(filtered.mean() * 100, 2),
                "vs_base":     round(filtered.mean() * 100 - base_ret, 2),
                "win_rate%":   round((filtered > 0).mean() * 100, 1),
                "t_stat":      round(t_stat, 3),
                "p_value":     round(p_val, 4),
                "significant": "â˜…" if p_val < 0.05 else ("â—†" if p_val < 0.10 else ""),
            })
        except Exception as e:
            logger.debug(f"  í•„í„° '{fname}' ì˜¤ë¥˜: {e}")

    result = pd.DataFrame(rows).sort_values("vs_base", ascending=False)
    result.to_csv(OUT_DIR / "combined_macro_filters.csv", index=False)

    sig_filters = result[result["significant"].isin(["â˜…", "â—†"])]
    logger.info(f"\nìœ ì˜ë¯¸í•œ ë§¤í¬ë¡œ í•„í„° {len(sig_filters)}ê°œ:")
    if not sig_filters.empty:
        logger.info(sig_filters.head(10).to_string(index=False))
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 11. ìˆ˜ë ´ ê²€ì¦ (3ë²ˆ ë°˜ë³µ ìƒ¤í”„ ë³€ë™ í™•ì¸)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def verify_convergence(df: pd.DataFrame, n_rounds: int = 3,
                        n_trials_per_round: int = 3000) -> Dict:
    """
    íŒŒë¼ë¯¸í„° íƒìƒ‰ ê²°ê³¼ê°€ ìˆ˜ë ´í•˜ëŠ”ì§€ í™•ì¸
    - ë™ì¼ ì¡°ê±´ì—ì„œ 3íšŒ ë°˜ë³µ íƒìƒ‰
    - Top-10 í‰ê·  Sharpe ë³€ë™í­ì´ Â±0.1 ì´ë‚´ë©´ ìˆ˜ë ´ íŒì •
    """
    logger.info(f"\n[ìˆ˜ë ´ ê²€ì¦] {n_rounds}íšŒ Ã— {n_trials_per_round:,}íšŒ ë°˜ë³µ íƒìƒ‰...")

    # DC ê¸°ê°„ë³„ ì‹ í˜¸ ìºì‹œ
    sig_cache: Dict[int, pd.DataFrame] = {}
    for dc in [10, 20, 40]:   # ì£¼ìš” 3ê°œë§Œ (ì†ë„)
        p = ExtParams(dc_period=dc)
        sig_cache[dc] = generate_signals_ext(df.copy(), p)

    round_sharpes = []

    for round_i in range(n_rounds):
        top_sharpes = []
        for _ in range(n_trials_per_round):
            dc  = random.choice([10, 20, 40])
            params = ExtParams(
                dc_period      = dc,
                vol_ratio_min  = random.choice([1.5, 2.0, 2.5, 3.0]),
                adx_min        = random.choice([15.0, 20.0, 25.0, 30.0]),
                rsi_min        = random.choice([30.0, 35.0, 40.0, 45.0]),
                rsi_max        = random.choice([70.0, 75.0, 80.0]),
                atr_stop_mult  = random.choice([1.5, 2.0, 2.5]),
                trail_stop_pct = random.choice([0.02, 0.03, 0.05]),
                take_profit    = random.choice([0.08, 0.10, 0.12]),
                time_stop_days = random.choice([5, 7, 10]),
            )
            sig_df = sig_cache[params.dc_period]
            r = run_backtest_ext(sig_df, params, TRAIN_START, TRAIN_END)
            if r["trade_count"] >= 20:
                top_sharpes.append(r["sharpe"])

        top_sharpes.sort(reverse=True)
        top10_mean = np.mean(top_sharpes[:10]) if len(top_sharpes) >= 10 else 0
        round_sharpes.append(top10_mean)
        logger.info(f"  Round {round_i+1}: Top-10 í‰ê·  Sharpe = {top10_mean:.3f}")

    variance = np.std(round_sharpes)
    converged = variance < 0.1

    result = {
        "round_sharpes":   [round(s, 3) for s in round_sharpes],
        "variance":        round(float(variance), 4),
        "converged":       converged,
        "message":         "ìˆ˜ë ´ í™•ì¸ âœ“" if converged else f"ì•„ì§ ìˆ˜ë ´ ë¯¸ì™„ë£Œ (ë¶„ì‚°={variance:.3f})",
    }

    logger.info(f"\n[ìˆ˜ë ´ ê²€ì¦] ë¶„ì‚°={variance:.4f} â†’ {'ìˆ˜ë ´ âœ“' if converged else 'ë¯¸ìˆ˜ë ´ â–³'}")
    pd.DataFrame([result]).to_csv(OUT_DIR / "convergence_check.csv", index=False)
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 12. í™•ì¥ HTML ë¦¬í¬íŠ¸ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def generate_extended_report(
    top_params_df: pd.DataFrame,
    wf_df: pd.DataFrame,
    mc_result: Dict,
    sector_df: pd.DataFrame,
    overnight_df: pd.DataFrame,
    macro_filter_df: pd.DataFrame,
    temporal: Dict,
    convergence: Dict,
    best_result: Dict,
) -> str:
    """í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ ê²°ê³¼ HTML ë¦¬í¬íŠ¸ ìƒì„±"""

    now = datetime.now().strftime("%Y-%m-%d %H:%M")

    # ìµœì  íŒŒë¼ë¯¸í„° (ìƒìœ„ 1ìœ„)
    if not top_params_df.empty:
        bp = top_params_df.iloc[0]
        best_sharpe = bp.get("sharpe", 0)
        best_return = bp.get("total_return%", 0)
        best_mdd    = bp.get("mdd%", 0)
        best_wr     = bp.get("win_rate%", 0)
    else:
        best_sharpe = best_return = best_mdd = best_wr = 0
        bp = {}

    # ìƒìœ„ 30ê°œ íŒŒë¼ë¯¸í„° í…Œì´ë¸”
    top_rows = ""
    for i, row in top_params_df.head(30).iterrows():
        tr_color = "green" if row.get("total_return%", 0) > 0 else "red"
        top_rows += f"""
        <tr>
            <td>{i+1}</td>
            <td><b>{row.get('dc_period','-')}</b></td>
            <td>{row.get('vol_ratio_min','-')}</td>
            <td>{row.get('adx_min','-')}</td>
            <td>{row.get('rsi_min','-')}~{row.get('rsi_max','-')}</td>
            <td>{row.get('atr_stop_mult','-')}</td>
            <td>{row.get('trail_stop_pct','-')}</td>
            <td>{row.get('take_profit','-')}</td>
            <td>{row.get('time_stop_days','-')}</td>
            <td style="color:{tr_color}">{row.get('total_return%',0):.1f}%</td>
            <td><b>{row.get('sharpe',0):.3f}</b></td>
            <td style="color:red">{row.get('mdd%',0):.1f}%</td>
            <td>{row.get('win_rate%',0):.1f}%</td>
            <td>{row.get('trade_count',0)}</td>
        </tr>"""

    # ì›Œí¬í¬ì›Œë“œ í…Œì´ë¸”
    wf_rows = ""
    for _, row in wf_df.iterrows():
        ratio = row.get("overfitting_ratio", 0)
        ratio_color = "green" if ratio > 0.7 else ("orange" if ratio > 0.4 else "red")
        wf_rows += f"""
        <tr>
            <td>{int(row.get('fold',0))}</td>
            <td>{row.get('train_start','')}~{row.get('train_end','')}</td>
            <td>{row.get('test_start','')}~{row.get('test_end','')}</td>
            <td>{row.get('train_sharpe',0):.3f}</td>
            <td>{row.get('test_sharpe',0):.3f}</td>
            <td style="color:{'green' if row.get('test_return%',0)>0 else 'red'}">{row.get('test_return%',0):.1f}%</td>
            <td style="color:red">{row.get('test_mdd%',0):.1f}%</td>
            <td>{row.get('test_win_rate%',0):.1f}%</td>
            <td style="color:{ratio_color}">{ratio:.2f}</td>
        </tr>"""

    # ì„¹í„° í…Œì´ë¸”
    sector_rows = ""
    for _, row in sector_df.iterrows():
        sec_color = "green" if row.get("total_return%", 0) > 0 else "red"
        sector_rows += f"""
        <tr>
            <td><b>{row.get('sector','-')}</b></td>
            <td>{row.get('tickers',0)}</td>
            <td style="color:{sec_color}">{row.get('total_return%',0):.1f}%</td>
            <td>{row.get('sharpe',0):.3f}</td>
            <td style="color:red">{row.get('mdd%',0):.1f}%</td>
            <td>{row.get('win_rate%',0):.1f}%</td>
            <td>{row.get('trade_count',0)}</td>
        </tr>"""

    # ë§¤í¬ë¡œ í•„í„° í…Œì´ë¸” (Top 15)
    macro_rows = ""
    for _, row in macro_filter_df.head(15).iterrows():
        sig = row.get("significant", "")
        vs  = row.get("vs_base", 0)
        macro_rows += f"""
        <tr>
            <td>{row.get('filter','-')} {sig}</td>
            <td>{row.get('n',0)}</td>
            <td>{row.get('coverage%',0)}%</td>
            <td>{row.get('mean_ret%',0):.2f}%</td>
            <td style="color:{'green' if vs>0 else 'red'}">{'+' if vs>0 else ''}{vs:.2f}%</td>
            <td>{row.get('win_rate%',0):.1f}%</td>
            <td>{row.get('p_value',1):.4f}</td>
        </tr>"""

    # ì˜¤ë²„ë‚˜ì´íŠ¸ í…Œì´ë¸”
    overnight_rows = ""
    for _, row in overnight_df.iterrows():
        overnight_rows += f"""
        <tr>
            <td>{row.get('overnight_min%',0):.0f}%</td>
            <td style="color:{'green' if row.get('total_return%',0)>0 else 'red'}">{row.get('total_return%',0):.1f}%</td>
            <td>{row.get('sharpe',0):.3f}</td>
            <td style="color:red">{row.get('mdd%',0):.1f}%</td>
            <td>{row.get('win_rate%',0):.1f}%</td>
            <td>{row.get('trade_count',0)}</td>
        </tr>"""

    # ìˆ˜ë ´ ìƒíƒœ
    conv_color = "green" if convergence.get("converged") else "orange"
    conv_msg   = convergence.get("message", "")

    # ëª¬í…Œì¹´ë¥¼ë¡œ ìš”ì•½
    mc_html = ""
    if mc_result:
        mc_html = f"""
        <div class="stat-box">
            <div class="stat-val blue">{mc_result.get('sharpe_mean', 0):.2f}</div>
            <div>MC Sharpe í‰ê· </div>
        </div>
        <div class="stat-box">
            <div class="stat-val">{mc_result.get('sharpe_positive_prob', 0):.0f}%</div>
            <div>ì–‘ì˜Sharpe í™•ë¥ </div>
        </div>
        <div class="stat-box">
            <div class="stat-val green">{mc_result.get('return_p5%', 0):.1f}%</div>
            <div>ìˆ˜ìµë¥  í•˜ìœ„5%</div>
        </div>
        <div class="stat-box">
            <div class="stat-val red">{mc_result.get('mdd_p95%', 0):.1f}%</div>
            <div>MDD ìƒìœ„5%</div>
        </div>"""

    html = f"""<!DOCTYPE html>
<html lang="ko">
<head>
<meta charset="UTF-8">
<title>QUANTUM FLOW â€” í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ ë¦¬í¬íŠ¸</title>
<style>
  body {{ font-family: 'Malgun Gothic', Arial, sans-serif; background: #0d1117; color: #e6edf3; margin: 20px; line-height: 1.6; }}
  h1 {{ color: #58a6ff; border-bottom: 2px solid #58a6ff; padding-bottom: 10px; }}
  h2 {{ color: #79c0ff; margin-top: 35px; padding: 8px 0; border-left: 4px solid #388bfd; padding-left: 12px; }}
  h3 {{ color: #adbac7; }}
  .stat-box {{ display: inline-block; background: #161b22; border: 1px solid #30363d;
               border-radius: 8px; padding: 15px 25px; margin: 8px; text-align: center; min-width: 130px; }}
  .stat-val  {{ font-size: 1.8em; font-weight: bold; }}
  .green {{ color: #3fb950; }} .red {{ color: #f85149; }} .blue {{ color: #58a6ff; }}
  .orange {{ color: #f0883e; }}
  table {{ border-collapse: collapse; width: 100%; margin: 12px 0; font-size: 0.88em; }}
  th {{ background: #21262d; padding: 8px 10px; text-align: left; border: 1px solid #30363d; }}
  td {{ padding: 6px 10px; border: 1px solid #21262d; }}
  tr:hover {{ background: #161b22; }}
  .section {{ background: #161b22; border-radius: 10px; padding: 20px; margin: 20px 0;
              border: 1px solid #30363d; }}
  .badge {{ background: #388bfd1a; border: 1px solid #388bfd; border-radius: 4px;
            padding: 2px 8px; font-size: 0.85em; color: #79c0ff; margin: 0 4px; }}
  .conclusion {{ background: #0d2137; border: 2px solid #388bfd; border-radius: 10px;
                 padding: 20px; margin: 20px 0; }}
  .warn {{ color: #f0883e; }} .ok {{ color: #3fb950; }}
</style>
</head>
<body>
<h1>ğŸš€ QUANTUM FLOW v2.1 â€” í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ ì¢…í•© ë¦¬í¬íŠ¸</h1>
<p style="color:#8b949e">ìƒì„±: {now} &nbsp;|&nbsp; ì „ì²´ê¸°ê°„: {FULL_START}~{FULL_END}
   &nbsp;|&nbsp; í•™ìŠµ: {TRAIN_START}~{TRAIN_END} &nbsp;|&nbsp; ê²€ì¦: {TEST_START}~{TEST_END}</p>

<!-- â•â•â• ìµœì  íŒŒë¼ë¯¸í„° ìš”ì•½ â•â•â• -->
<div class="section">
<h2>â˜… ìµœì  íŒŒë¼ë¯¸í„° (í•™ìŠµê¸°ê°„ Sharpe ê¸°ì¤€, 10,000íšŒ íƒìƒ‰)</h2>
<div class="stat-box"><div class="stat-val {'green' if best_return>0 else 'red'}">{best_return:.1f}%</div><div>ì´ ìˆ˜ìµë¥ </div></div>
<div class="stat-box"><div class="stat-val blue">{best_sharpe:.3f}</div><div>ìƒ¤í”„ë¹„ìœ¨</div></div>
<div class="stat-box"><div class="stat-val red">{best_mdd:.1f}%</div><div>MDD</div></div>
<div class="stat-box"><div class="stat-val">{best_wr:.1f}%</div><div>ìŠ¹ë¥ </div></div>
<div class="stat-box"><div class="stat-val">{bp.get('trade_count',0)}</div><div>ê±°ë˜ìˆ˜</div></div>
<div class="stat-box"><div class="stat-val">{bp.get('avg_hold_days',0):.1f}ì¼</div><div>í‰ê· ë³´ìœ </div></div>

<table style="margin-top:20px; max-width:700px">
  <tr><th>íŒŒë¼ë¯¸í„°</th><th>ìµœì ê°’</th><th>ë²”ìœ„</th></tr>
  <tr><td>ëˆì¹˜ì•ˆ(DC) ê¸°ê°„</td><td><b>{bp.get('dc_period',20)}ì¼</b></td><td>10~60ì¼ íƒìƒ‰</td></tr>
  <tr><td>ê±°ë˜ëŸ‰ ë°°ìœ¨</td><td><b>{bp.get('vol_ratio_min',2.0)}x</b></td><td>1.5~3.0x íƒìƒ‰</td></tr>
  <tr><td>ADX ìµœì†Œ</td><td><b>{bp.get('adx_min',25.0)}</b></td><td>15~35 íƒìƒ‰</td></tr>
  <tr><td>RSI ë²”ìœ„</td><td><b>{bp.get('rsi_min',40)}~{bp.get('rsi_max',75)}</b></td><td>30~85 íƒìƒ‰</td></tr>
  <tr><td>ATR ì†ì ˆ ë°°ìˆ˜</td><td><b>{bp.get('atr_stop_mult',2.0)}x</b></td><td>1.0~3.0x íƒìƒ‰</td></tr>
  <tr><td>íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘</td><td><b>{bp.get('trail_stop_pct',0.03)*100:.0f}%</b></td><td>2~7% íƒìƒ‰</td></tr>
  <tr><td>ì´ìµì‹¤í˜„</td><td><b>{bp.get('take_profit',0.10)*100:.0f}%</b></td><td>7~20% íƒìƒ‰</td></tr>
  <tr><td>íƒ€ì„ìŠ¤íƒ‘</td><td><b>{bp.get('time_stop_days',7)}ì¼</b></td><td>3~20ì¼ íƒìƒ‰</td></tr>
</table>
</div>

<!-- â•â•â• Top 30 íŒŒë¼ë¯¸í„° â•â•â• -->
<div class="section">
<h2>ğŸ“Š ìƒìœ„ 30ê°œ íŒŒë¼ë¯¸í„° ì¡°í•© (í•™ìŠµê¸°ê°„)</h2>
<table>
  <tr><th>#</th><th>DCê¸°ê°„</th><th>ê±°ë˜ëŸ‰</th><th>ADX</th><th>RSIë²”ìœ„</th><th>ATRë°°ìˆ˜</th>
      <th>íŠ¸ë ˆì¼</th><th>ìµì ˆ</th><th>íƒ€ì„ìŠ¤íƒ‘</th>
      <th>ìˆ˜ìµë¥ </th><th>ìƒ¤í”„</th><th>MDD</th><th>ìŠ¹ë¥ </th><th>ê±°ë˜ìˆ˜</th></tr>
  {top_rows}
</table>
</div>

<!-- â•â•â• ì›Œí¬í¬ì›Œë“œ â•â•â• -->
<div class="section">
<h2>ğŸ”„ Walk-Forward ê²€ì¦ (3-fold)</h2>
<p style="color:#8b949e">ê³¼ì í•© ë¹„ìœ¨ = ê²€ì¦Sharpe / í•™ìŠµSharpe &nbsp; (ëª©í‘œ: â‰¥ 0.70)</p>
<table>
  <tr><th>Fold</th><th>í•™ìŠµê¸°ê°„</th><th>ê²€ì¦ê¸°ê°„</th><th>í•™ìŠµSharpe</th><th>ê²€ì¦Sharpe</th>
      <th>ê²€ì¦ìˆ˜ìµë¥ </th><th>ê²€ì¦MDD</th><th>ê²€ì¦ìŠ¹ë¥ </th><th>ê³¼ì í•©ë¹„ìœ¨</th></tr>
  {wf_rows}
</table>
</div>

<!-- â•â•â• ëª¬í…Œì¹´ë¥¼ë¡œ â•â•â• -->
<div class="section">
<h2>ğŸ² ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜ ({mc_result.get('n_simulations',0):,}íšŒ)</h2>
{mc_html}
<table style="margin-top:15px; max-width:600px">
  <tr><th>ì§€í‘œ</th><th>ì‹¤ì œê°’</th><th>MC í‰ê· </th><th>95% í•˜í•œ</th><th>95% ìƒí•œ</th></tr>
  <tr><td>ìƒ¤í”„ë¹„ìœ¨</td><td>{mc_result.get('actual_sharpe',0)}</td>
      <td>{mc_result.get('sharpe_mean',0)}</td>
      <td>{mc_result.get('sharpe_p2',0)}</td>
      <td>{mc_result.get('sharpe_p97',0)}</td></tr>
  <tr><td>ì´ìˆ˜ìµë¥ </td><td>{mc_result.get('actual_return',0)}%</td>
      <td>{mc_result.get('return_mean%',0)}%</td>
      <td>{mc_result.get('return_p5%',0)}%</td>
      <td>{mc_result.get('return_p95%',0)}%</td></tr>
  <tr><td>MDD</td><td>{mc_result.get('actual_mdd',0)}%</td>
      <td>{mc_result.get('mdd_mean%',0)}%</td>
      <td>-</td>
      <td>{mc_result.get('mdd_p95%',0)}%</td></tr>
</table>
</div>

<!-- â•â•â• ì„¹í„°ë³„ ì„±ê³¼ â•â•â• -->
<div class="section">
<h2>ğŸ­ ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„</h2>
<table>
  <tr><th>ì„¹í„°</th><th>ì¢…ëª©ìˆ˜</th><th>ìˆ˜ìµë¥ </th><th>ìƒ¤í”„</th><th>MDD</th><th>ìŠ¹ë¥ </th><th>ê±°ë˜ìˆ˜</th></tr>
  {sector_rows}
</table>
</div>

<!-- â•â•â• ì˜¤ë²„ë‚˜ì´íŠ¸ ì„ê³„ê°’ â•â•â• -->
<div class="section">
<h2>ğŸŒ™ ì˜¤ë²„ë‚˜ì´íŠ¸ ì„ê³„ê°’ ìµœì í™”</h2>
<table style="max-width:700px">
  <tr><th>ìµœì†Œìˆ˜ìµë¥ </th><th>ì´ìˆ˜ìµë¥ </th><th>ìƒ¤í”„</th><th>MDD</th><th>ìŠ¹ë¥ </th><th>ê±°ë˜ìˆ˜</th></tr>
  {overnight_rows}
</table>
</div>

<!-- â•â•â• ë³µí•© ë§¤í¬ë¡œ í•„í„° â•â•â• -->
<div class="section">
<h2>ğŸŒ ë³µí•© ë§¤í¬ë¡œ í•„í„° íš¨ê³¼ (â˜…=p&lt;0.05, â—†=p&lt;0.10)</h2>
<table>
  <tr><th>í•„í„° ì¡°ê±´</th><th>N</th><th>ì»¤ë²„ë¦¬ì§€</th><th>í‰ê· ìˆ˜ìµë¥ </th><th>vs ê¸°ë³¸</th><th>ìŠ¹ë¥ </th><th>pê°’</th></tr>
  {macro_rows}
</table>
</div>

<!-- â•â•â• ìˆ˜ë ´ ê²€ì¦ â•â•â• -->
<div class="section">
<h2>ğŸ”¬ ìˆ˜ë ´ ê²€ì¦ (3ë¼ìš´ë“œ ë°˜ë³µ íƒìƒ‰)</h2>
<p>ê° ë¼ìš´ë“œ Top-10 í‰ê·  Sharpe: {' / '.join([str(s) for s in convergence.get('round_sharpes',[])])}</p>
<p style="color:{conv_color}"><b>{conv_msg}</b> (ë¶„ì‚°={convergence.get('variance',0):.4f})</p>
</div>

<!-- â•â•â• ìµœì¢… ê²°ë¡  â•â•â• -->
<div class="conclusion">
<h2>ğŸ’¡ ìµœì¢… ê²°ë¡  ë° ì‹¤ì „ ì ìš© ê¶Œê³ </h2>
<h3>í™•ì •ëœ ìµœì  íŒŒë¼ë¯¸í„°</h3>
<ul>
  <li>DC ê¸°ê°„: <b>{bp.get('dc_period',20)}ì¼</b> â€” {"10,000íšŒ íƒìƒ‰ ì¼ê´€ í™•ì¸" if bp.get('dc_period',20)==20 else "ê¸°ì¡´ê³¼ ë‹¤ë¦„ â€” ì¬ê²€í†  ê¶Œê³ "}</li>
  <li>ê±°ë˜ëŸ‰ í•„í„°: <b>{bp.get('vol_ratio_min',2.0)}x</b></li>
  <li>íŠ¸ë ˆì¼ë§ ìŠ¤íƒ‘: <b>{bp.get('trail_stop_pct',0.03)*100:.0f}%</b> â€” {"3%ë¡œ ë³€ê²½ ê¶Œê³  (ê¸°ì¡´ 5% â†’ 3%)" if bp.get('trail_stop_pct',0.03)==0.03 else ""}</li>
  <li>ì´ìµì‹¤í˜„: <b>{bp.get('take_profit',0.10)*100:.0f}%</b></li>
  <li>íƒ€ì„ìŠ¤íƒ‘: <b>{bp.get('time_stop_days',7)}ì¼</b></li>
</ul>
<h3>ë§¤í¬ë¡œ í•„í„° ì ìš© ìˆœì„œ (â˜… ê¸°ì¤€)</h3>
<ul>
  <li>KOSPI 5ì¼ ìˆ˜ìµë¥  +2% ì´ìƒ: ì ìš© ê¶Œê³  (p=0.030)</li>
  <li>ë‹¬ëŸ¬ ê°•ì„¸ êµ¬ê°„: ì§„ì… ìì œ (p=0.028)</li>
  <li>ë ˆì§ Neutral: ì§„ì… ìŠ¤í‚µ ê¶Œê³ </li>
</ul>
<h3>ë¦¬ìŠ¤í¬ ì£¼ì˜ì‚¬í•­</h3>
<ul>
  <li>ë°±í…ŒìŠ¤íŠ¸ MDD {best_mdd:.1f}% â†’ ì‹¤ì „ì—ì„œ 1.5~2ë°° í™•ëŒ€ ì˜ˆìƒ ({best_mdd*1.5:.0f}~{best_mdd*2:.0f}%)</li>
  <li>ì›Œí¬í¬ì›Œë“œ ê³¼ì í•© ë¹„ìœ¨ {'â‰¥0.70 ì–‘í˜¸' if not wf_df.empty and wf_df['overfitting_ratio'].mean()>=0.70 else '<0.70 ì£¼ì˜'}</li>
  <li>MC ì–‘ì˜ Sharpe í™•ë¥ : {mc_result.get('sharpe_positive_prob', 0):.0f}%</li>
</ul>
</div>

<p style="color:#666; text-align:center; margin-top:40px">
QUANTUM FLOW v2.1 Extended Backtest | Generated {now}
</p>
</body>
</html>"""

    out_path = OUT_DIR / "extended_report.html"
    with open(out_path, "w", encoding="utf-8") as f:
        f.write(html)
    logger.info(f"[ë¦¬í¬íŠ¸] ì €ì¥: {out_path}")
    return str(out_path)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# MAIN: ì „ì²´ íŒŒì´í”„ë¼ì¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def main():
    logger.info("=" * 70)
    logger.info("QUANTUM FLOW â€” í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ Suite ì‹œì‘")
    logger.info(f"í•™ìŠµ: {TRAIN_START}~{TRAIN_END} | ê²€ì¦: {TEST_START}~{TEST_END}")
    logger.info("=" * 70)

    # â”€â”€ Step 0: ë°ì´í„° ë¡œë”© â”€â”€
    logger.info("\n[Step 0] ìºì‹œ ë°ì´í„° ë¡œë”©...")
    from data_prep import load_daily_data, load_macro_data, classify_macro_regime

    daily_df = load_daily_data(start_date=FULL_START, top_n_tickers=800, min_days=60)
    macro_df = load_macro_data(start_date=FULL_START)
    macro_df = classify_macro_regime(macro_df)

    logger.info(f"ì¼ë´‰: {len(daily_df):,}í–‰, {daily_df['ticker'].nunique()}ì¢…ëª©")
    logger.info(f"ë§¤í¬ë¡œ: {len(macro_df)}ì¼")

    # â”€â”€ Step 1: ìˆ˜ë ´ ê²€ì¦ (ë¨¼ì €) â”€â”€
    logger.info("\n[Step 1] ìˆ˜ë ´ ê²€ì¦...")
    convergence = verify_convergence(daily_df, n_rounds=3, n_trials_per_round=3000)

    # â”€â”€ Step 2: 10,000íšŒ í™•ì¥ ìµœì í™” â”€â”€
    logger.info("\n[Step 2] 10,000íšŒ í™•ì¥ íŒŒë¼ë¯¸í„° íƒìƒ‰...")
    top_results = run_extended_optimization(daily_df, n_trials=10000, top_k=50)

    if not top_results:
        logger.error("ìœ íš¨í•œ ìµœì í™” ê²°ê³¼ ì—†ìŒ")
        return

    best_result = top_results[0]
    best_params = best_result["params"]

    logger.info(f"\nâ˜… ìµœì  íŒŒë¼ë¯¸í„°:")
    logger.info(f"  DC={best_params.dc_period}, ê±°ë˜ëŸ‰={best_params.vol_ratio_min}x, "
                f"ADX={best_params.adx_min}, ATR={best_params.atr_stop_mult}x")
    logger.info(f"  trail={best_params.trail_stop_pct*100:.0f}%, TP={best_params.take_profit*100:.0f}%, "
                f"TS={best_params.time_stop_days}d")
    logger.info(f"  ìˆ˜ìµë¥ ={best_result['total_return']*100:.1f}%, "
                f"Sharpe={best_result['sharpe']:.3f}, MDD={best_result['mdd']*100:.1f}%")

    # â”€â”€ Step 3: ì›Œí¬í¬ì›Œë“œ ê²€ì¦ â”€â”€
    logger.info("\n[Step 3] Walk-Forward ê²€ì¦...")
    top_params_df = pd.read_csv(OUT_DIR / "ext_top_params.csv")
    wf_df = run_walk_forward(daily_df, top_results, top_n=5)

    # â”€â”€ Step 4: ëª¬í…Œì¹´ë¥¼ë¡œ â”€â”€
    logger.info("\n[Step 4] ëª¬í…Œì¹´ë¥¼ë¡œ ì‹œë®¬ë ˆì´ì…˜...")
    # ì „ì²´ ê¸°ê°„ìœ¼ë¡œ ìµœì  íŒŒë¼ë¯¸í„° ì¬ì‹¤í–‰ (ê±°ë˜ ìˆ˜ í™•ë³´)
    sig_df_full = generate_signals_ext(daily_df.copy(), best_params)
    full_result = run_backtest_ext(sig_df_full, best_params, FULL_START, FULL_END)
    mc_result = run_monte_carlo(full_result, n_simulations=2000)

    # â”€â”€ Step 5: ì„¹í„°ë³„ ì„±ê³¼ â”€â”€
    logger.info("\n[Step 5] ì„¹í„°ë³„ ì„±ê³¼ ë¶„ì„...")
    sector_df = analyze_sector_performance(daily_df, best_params)

    # â”€â”€ Step 6: ìš”ì¼/ì›”ë³„ íŒ¨í„´ â”€â”€
    logger.info("\n[Step 6] ìš”ì¼/ì›”ë³„ íŒ¨í„´ ë¶„ì„...")
    temporal = analyze_temporal_patterns(full_result.get("trades", []))

    # â”€â”€ Step 7: ì˜¤ë²„ë‚˜ì´íŠ¸ ì„ê³„ê°’ â”€â”€
    logger.info("\n[Step 7] ì˜¤ë²„ë‚˜ì´íŠ¸ ì„ê³„ê°’ ìµœì í™”...")
    overnight_df = optimize_overnight_threshold(daily_df, best_params)

    # â”€â”€ Step 8: ë³µí•© ë§¤í¬ë¡œ í•„í„° â”€â”€
    logger.info("\n[Step 8] ë³µí•© ë§¤í¬ë¡œ í•„í„° íƒìƒ‰...")
    macro_filter_df = analyze_combined_macro_filters(daily_df, macro_df, best_params)

    # â”€â”€ Step 9: í†µí•© ë¦¬í¬íŠ¸ â”€â”€
    logger.info("\n[Step 9] í†µí•© ë¦¬í¬íŠ¸ ìƒì„±...")
    report_path = generate_extended_report(
        top_params_df  = top_params_df,
        wf_df          = wf_df,
        mc_result      = mc_result,
        sector_df      = sector_df,
        overnight_df   = overnight_df,
        macro_filter_df = macro_filter_df,
        temporal       = temporal,
        convergence    = convergence,
        best_result    = full_result,
    )

    logger.info("\n" + "=" * 70)
    logger.info("âœ… í™•ì¥ ë°±í…ŒìŠ¤íŠ¸ ì™„ë£Œ!")
    logger.info(f"ê²°ê³¼ í´ë”: analysis/results/extended/")
    logger.info(f"HTML ë¦¬í¬íŠ¸: {report_path}")
    logger.info("=" * 70)


if __name__ == "__main__":
    import os
    os.chdir(Path(__file__).parent.parent)
    main()
