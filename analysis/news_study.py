"""
news_study.py â€” Track 3: ë‰´ìŠ¤ ê°ì„± Ã— ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ ë¶„ì„
================================================================================
í˜„ì¬ ìƒíƒœ:
  - ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ (outputs/news_price_log/ ë¯¸ìˆ˜ì§‘)
  - ëŒ€ì‹  ê³¼ê±° ì¼ë´‰ ë°ì´í„° ê¸°ë°˜ìœ¼ë¡œ 'ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ'ë¥¼ êµ¬ì„±í•˜ì—¬ ë¶„ì„

ë¶„ì„ ë°©ë²•:
  1. ê¸‰ë“±ì¼(+5% ì´ìƒ) = í˜¸ì¬ ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ
  2. ê¸‰ë½ì¼(-5% ì´í•˜) = ì•…ì¬ ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ
  3. ê±°ë˜ëŸ‰ ê¸‰ì¦(vol_ratio > 3.0) = ë‰´ìŠ¤ ì´ë²¤íŠ¸ ë°œìƒ í”„ë¡ì‹œ
  4. ê¸°ìˆ ì  ì‹ í˜¸ì¼ = QUANTUM FLOW ì§„ì… ì‹ í˜¸ ë°œìƒ
  5. ê° ì´ë²¤íŠ¸ ì „í›„ 5/10/20ì¼ ìˆ˜ìµë¥  ë¶„í¬ ë¶„ì„

ì‹¤ì „ ë‰´ìŠ¤ ë°ì´í„° ìˆ˜ì§‘ ì‹œ ì´ ëª¨ë“ˆë¡œ ì§ì ‘ ë¶„ì„ ê°€ëŠ¥í•˜ë„ë¡ ì¸í„°í˜ì´ìŠ¤ ì„¤ê³„.
"""
import logging
import numpy as np
import pandas as pd
from pathlib import Path
from typing import Dict, List, Optional
from scipy import stats

logger = logging.getLogger("analysis.news_study")

OUT_DIR = Path(__file__).parent / "results" / "extended"
OUT_DIR.mkdir(parents=True, exist_ok=True)

# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 1. ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ ìƒì„±
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def build_news_proxy(df: pd.DataFrame) -> pd.DataFrame:
    """
    ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ëŒ€ì‹  ê°€ê²©/ê±°ë˜ëŸ‰ íŒ¨í„´ìœ¼ë¡œ ë‰´ìŠ¤ ì´ë²¤íŠ¸ ê·¼ì‚¬.

    ë°˜í™˜ ì»¬ëŸ¼:
      - event_bullish:  ë‹¹ì¼ +5% ì´ìƒ ê¸‰ë“± (í˜¸ì¬ ë‰´ìŠ¤ í”„ë¡ì‹œ)
      - event_bearish:  ë‹¹ì¼ -5% ì´í•˜ ê¸‰ë½ (ì•…ì¬ ë‰´ìŠ¤ í”„ë¡ì‹œ)
      - event_volume:   ê±°ë˜ëŸ‰ 3ë°° ì´ìƒ (ì–´ë–¤ ì¢…ë¥˜ë“  ë‰´ìŠ¤ ì´ë²¤íŠ¸)
      - event_any:      ìœ„ ì…‹ ì¤‘ í•˜ë‚˜ë¼ë„ í•´ë‹¹
    """
    out = df.copy()

    # ë‹¹ì¼ ìˆ˜ìµë¥ 
    if "ret1d" not in out.columns:
        out["ret1d"] = out.groupby("ticker")["close"].pct_change()

    out["event_bullish"] = out["ret1d"] >= 0.05
    out["event_bearish"] = out["ret1d"] <= -0.05
    out["event_volume"]  = out["vol_ratio"] >= 3.0
    out["event_any"]     = out["event_bullish"] | out["event_bearish"] | out["event_volume"]

    # ì´ë²¤íŠ¸ ê°•ë„ ì ìˆ˜ (-1.0 ~ +1.0)
    out["event_score"] = np.where(
        out["event_bullish"], out["ret1d"].clip(0, 0.15) / 0.15,
        np.where(out["event_bearish"], out["ret1d"].clip(-0.15, 0) / 0.15, 0.0)
    )

    return out


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 2. ì´ë²¤íŠ¸ í›„ ì „ì§„ìˆ˜ìµë¥  ë¶„í¬ ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_event_returns(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê° ì´ë²¤íŠ¸ ìœ í˜•ë³„ ì „ì§„ìˆ˜ìµë¥ (1/3/5/10d) ë¶„í¬.
    ì´ë²¤íŠ¸ê°€ ìˆëŠ” ë‚ ê³¼ ì—†ëŠ” ë‚ ì˜ í†µê³„ì  ì°¨ì´ ê²€ì •.
    """
    fwd_cols = [c for c in ["fwd_ret1", "fwd_ret3", "fwd_ret5", "fwd_ret10"] if c in df.columns]
    event_types = {
        "í˜¸ì¬(+5%â†‘)": "event_bullish",
        "ì•…ì¬(-5%â†“)": "event_bearish",
        "ê±°ë˜ëŸ‰í­ì¦(3ë°°â†‘)": "event_volume",
        "ì´ë²¤íŠ¸ì „ì²´": "event_any",
    }

    rows = []
    for event_name, event_col in event_types.items():
        if event_col not in df.columns:
            continue

        ev   = df[df[event_col] == True]
        noev = df[df[event_col] == False]

        for fwd in fwd_cols:
            ev_rets   = ev[fwd].dropna()
            noev_rets = noev[fwd].dropna()
            if len(ev_rets) < 10:
                continue

            t_stat, p_val = stats.ttest_ind(ev_rets, noev_rets, equal_var=False)
            horizon = fwd.replace("fwd_ret", "").replace("d", "")

            rows.append({
                "ì´ë²¤íŠ¸":       event_name,
                "ì „ì§„ìˆ˜ìµë¥ ":   f"{horizon}ì¼",
                "n_ì´ë²¤íŠ¸":     len(ev_rets),
                "n_ì¼ë°˜":       len(noev_rets),
                "ì´ë²¤íŠ¸_í‰ê· %": round(ev_rets.mean() * 100, 2),
                "ì¼ë°˜_í‰ê· %":   round(noev_rets.mean() * 100, 2),
                "ì°¨ì´%":        round((ev_rets.mean() - noev_rets.mean()) * 100, 2),
                "ì´ë²¤íŠ¸_ìŠ¹ë¥ %": round((ev_rets > 0).mean() * 100, 1),
                "ì¼ë°˜_ìŠ¹ë¥ %":   round((noev_rets > 0).mean() * 100, 1),
                "t_stat":       round(t_stat, 3),
                "p_value":      round(p_val, 4),
                "ìœ ì˜":         "â˜…" if p_val < 0.05 else ("â—†" if p_val < 0.10 else ""),
            })

    result = pd.DataFrame(rows)
    result.to_csv(OUT_DIR / "news_event_returns.csv", index=False)
    logger.info(f"\n[ë‰´ìŠ¤ ì´ë²¤íŠ¸] ì „ì§„ìˆ˜ìµë¥  ë¶„ì„:\n{result[result['ìœ ì˜']!=''].to_string(index=False)}")
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 3. ì´ë²¤íŠ¸ + ê¸°ìˆ ì  ì‹ í˜¸ ê²°í•© íš¨ê³¼
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_signal_plus_event(df: pd.DataFrame) -> pd.DataFrame:
    """
    QUANTUM FLOW ì§„ì… ì‹ í˜¸ Ã— ë‰´ìŠ¤ ì´ë²¤íŠ¸ ê²°í•© íš¨ê³¼ ë¶„ì„.
    ì‹ í˜¸ë§Œ ìˆëŠ” ê²½ìš° vs ì‹ í˜¸+í˜¸ì¬ì´ë²¤íŠ¸ vs ì‹ í˜¸+ì•…ì¬ì´ë²¤íŠ¸
    """
    if "entry_signal" not in df.columns:
        logger.warning("entry_signal ì»¬ëŸ¼ ì—†ìŒ â€” DC20/vol2/adx25 ê¸°ì¤€ìœ¼ë¡œ ìƒì„±")
        df = df.copy()
        dc_col = "dc_high20"
        if dc_col not in df.columns:
            df[dc_col] = df.groupby("ticker")["high"].transform(
                lambda x: x.shift(1).rolling(20).max()
            )
        df["entry_signal"] = (
            (df["close"] > df[dc_col]) &
            (df["vol_ratio"] >= 2.0) &
            (df["adx14"] >= 25) &
            (df["close"] > df["ma60"])
        )

    fwd = "fwd_ret5" if "fwd_ret5" in df.columns else None
    if not fwd:
        return pd.DataFrame()

    base_sig = df[df["entry_signal"] == True]
    base_ret = base_sig[fwd].dropna().mean() * 100
    base_n   = len(base_sig[fwd].dropna())

    logger.info(f"\n[ì‹ í˜¸+ì´ë²¤íŠ¸ ê²°í•©] ë² ì´ìŠ¤ë¼ì¸: {base_ret:.2f}%, N={base_n}")

    combos = {
        "ì‹ í˜¸ë§Œ":                    ("entry_signal", None),
        "ì‹ í˜¸ + í˜¸ì¬(ë‹¹ì¼+5%â†‘)":    ("entry_signal", "event_bullish"),
        "ì‹ í˜¸ + ì•…ì¬(ë‹¹ì¼-5%â†“)":    ("entry_signal", "event_bearish"),
        "ì‹ í˜¸ + ê±°ë˜ëŸ‰í­ì¦(3ë°°â†‘)":  ("entry_signal", "event_volume"),
        "ì‹ í˜¸ + ì´ë²¤íŠ¸ì—†ìŒ":         ("entry_signal", "no_event"),
        "ì‹ í˜¸ ì—†ìŒ":                 ("no_signal",    None),
    }

    rows = []
    for combo_name, (sig_cond, event_cond) in combos.items():
        if sig_cond == "entry_signal":
            sub = df[df["entry_signal"] == True].copy()
        else:
            sub = df[df["entry_signal"] == False].copy()

        if event_cond == "no_event":
            sub = sub[sub["event_any"] == False]
        elif event_cond and event_cond in sub.columns:
            sub = sub[sub[event_cond] == True]

        rets = sub[fwd].dropna()
        if len(rets) < 5:
            continue

        t_stat, p_val = stats.ttest_ind(rets, base_sig[fwd].dropna(), equal_var=False)
        rows.append({
            "ì¡°í•©":         combo_name,
            "n":            len(rets),
            "í‰ê· ìˆ˜ìµë¥ %":  round(rets.mean() * 100, 2),
            "vs_ê¸°ë³¸ì‹ í˜¸":  round(rets.mean() * 100 - base_ret, 2),
            "ìŠ¹ë¥ %":        round((rets > 0).mean() * 100, 1),
            "std%":         round(rets.std() * 100, 2),
            "t_stat":       round(t_stat, 3),
            "p_value":      round(p_val, 4),
            "ìœ ì˜":         "â˜…" if p_val < 0.05 else ("â—†" if p_val < 0.10 else ""),
        })

    result = pd.DataFrame(rows)
    result.to_csv(OUT_DIR / "signal_event_combo.csv", index=False)
    logger.info(f"\n{result.to_string(index=False)}")
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 4. ì´ë²¤íŠ¸ ì´í›„ íšŒë³µ/ì¶”ê°€í•˜ë½ íŒ¨í„´ ë¶„ì„
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def analyze_event_recovery(df: pd.DataFrame) -> pd.DataFrame:
    """
    ê¸‰ë“±/ê¸‰ë½ ì´ë²¤íŠ¸ ì´í›„ íŒ¨í„´:
    - ê¸‰ë“± í›„: ì¶”ê°€ ìƒìŠ¹ vs ë˜ëŒë¦¼
    - ê¸‰ë½ í›„: íšŒë³µ vs ì¶”ê°€ í•˜ë½
    ë°˜ë“±/ë°˜ë½ íƒ€ì´ë° íƒìƒ‰
    """
    rows = []

    for event_type, event_col, direction in [
        ("í˜¸ì¬(+5%â†‘)", "event_bullish", "up"),
        ("ì•…ì¬(-5%â†“)", "event_bearish", "down"),
    ]:
        if event_col not in df.columns:
            continue

        ev = df[df[event_col] == True]
        fwd_cols = ["fwd_ret1", "fwd_ret3", "fwd_ret5", "fwd_ret10"]

        for fwd in [c for c in fwd_cols if c in ev.columns]:
            horizon = fwd.replace("fwd_ret", "").replace("d", "")
            rets = ev[fwd].dropna()
            if len(rets) < 10:
                continue

            # ê¸‰ë“± í›„ ì¶”ê°€ ìƒìŠ¹ ë¹„ìœ¨ (ëª¨ë©˜í…€)
            momentum_rate = (rets > 0).mean() * 100 if direction == "up" else (rets < 0).mean() * 100
            # ë˜ëŒë¦¼ ë¹„ìœ¨ (ì—­ì¶”ì„¸)
            reversal_rate = 100 - momentum_rate

            rows.append({
                "ì´ë²¤íŠ¸":          event_type,
                "ì „ì§„ê¸°ê°„":        f"{horizon}ì¼",
                "n":               len(rets),
                "í‰ê· ìˆ˜ìµë¥ %":     round(rets.mean() * 100, 2),
                "ëª¨ë©˜í…€ ì§€ì†%":    round(momentum_rate, 1),
                "ë˜ëŒë¦¼%":         round(reversal_rate, 1),
                "q25%":            round(rets.quantile(0.25) * 100, 2),
                "q75%":            round(rets.quantile(0.75) * 100, 2),
            })

    result = pd.DataFrame(rows)
    result.to_csv(OUT_DIR / "event_recovery_pattern.csv", index=False)
    logger.info(f"\n[ì´ë²¤íŠ¸ í›„ íŒ¨í„´]:\n{result.to_string(index=False)}")
    return result


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 5. ì‹¤ì „ ë‰´ìŠ¤ ë¡œê·¸ íŒŒì‹± (ì‹¤ì „ ë°ì´í„° ìˆ˜ì§‘ í›„ ì‚¬ìš©)
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def load_real_news_log(log_dir: str = "outputs/news_price_log") -> Optional[pd.DataFrame]:
    """
    news_monitor.pyê°€ ìˆ˜ì§‘í•œ ì‹¤ì œ ë‰´ìŠ¤ ë¡œê·¸ íŒŒì‹±.
    íŒŒì¼ í˜•ì‹: {log_dir}/{date}/{code}.jsonl

    ë°˜í™˜: {
      "ticker", "date", "news_score",  # ê°ì„±ì ìˆ˜ (POSITIVE=1, NEUTRAL=0, WARNING=-1, CRITICAL=-2)
      "price_at_news", "entry_signal", "fwd_ret5"
    }
    """
    import json, glob
    from pathlib import Path

    log_path = Path(log_dir)
    if not log_path.exists():
        logger.info(f"ë‰´ìŠ¤ ë¡œê·¸ ê²½ë¡œ ì—†ìŒ: {log_dir} â€” ì‹¤ì „ ìˆ˜ì§‘ í›„ ì¬ì‹¤í–‰ í•„ìš”")
        return None

    records = []
    for jsonl_file in glob.glob(str(log_path / "**/*.jsonl"), recursive=True):
        try:
            with open(jsonl_file, "r", encoding="utf-8") as f:
                for line in f:
                    line = line.strip()
                    if not line:
                        continue
                    item = json.loads(line)
                    # news_monitor.py ë¡œê·¸ í˜•ì‹ì— ë§ì¶¤
                    sentiment = item.get("sentiment", "NEUTRAL")
                    score = {"POSITIVE": 1, "NEUTRAL": 0,
                             "WARNING": -1, "CRITICAL": -2}.get(sentiment, 0)
                    records.append({
                        "ticker":        item.get("code", ""),
                        "date":          item.get("date", ""),
                        "news_score":    score,
                        "sentiment":     sentiment,
                        "price":         item.get("price", 0),
                        "reason":        item.get("trigger_reason", ""),
                        "article_count": item.get("article_count", 0),
                    })
        except Exception as e:
            logger.debug(f"ë¡œê·¸ íŒŒì‹± ì‹¤íŒ¨ ({jsonl_file}): {e}")

    if not records:
        logger.info("ë‰´ìŠ¤ ë¡œê·¸ ë°ì´í„° ì—†ìŒ")
        return None

    df = pd.DataFrame(records)
    logger.info(f"ë‰´ìŠ¤ ë¡œê·¸ ë¡œë“œ: {len(df):,}ê±´, {df['ticker'].nunique()}ì¢…ëª©")
    return df


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 6. í†µí•© ë‰´ìŠ¤ ë¶„ì„ ë¦¬í¬íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def run_news_study(daily_df: pd.DataFrame,
                    news_log_dir: str = "outputs/news_price_log") -> Dict:
    """
    ë‰´ìŠ¤ Ã— ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ ì „ì²´ ë¶„ì„ íŒŒì´í”„ë¼ì¸.
    """
    logger.info("=" * 60)
    logger.info("Track 3: ë‰´ìŠ¤ ê°ì„± Ã— ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ ë¶„ì„")
    logger.info("=" * 60)

    # ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ ìƒì„±
    logger.info("\n[1] ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ ìƒì„±...")
    df = build_news_proxy(daily_df)

    event_counts = {
        "í˜¸ì¬(+5%â†‘)":     int(df["event_bullish"].sum()),
        "ì•…ì¬(-5%â†“)":     int(df["event_bearish"].sum()),
        "ê±°ë˜ëŸ‰í­ì¦(3ë°°â†‘)": int(df["event_volume"].sum()),
        "ì´ë²¤íŠ¸ì „ì²´":     int(df["event_any"].sum()),
        "ì „ì²´ ë°ì´í„°":    len(df),
    }
    for k, v in event_counts.items():
        logger.info(f"  {k}: {v:,}ê±´ ({v/len(df)*100:.1f}%)")

    results = {}

    # ì´ë²¤íŠ¸ë³„ ì „ì§„ìˆ˜ìµë¥  ë¶„ì„
    logger.info("\n[2] ì´ë²¤íŠ¸ë³„ ì „ì§„ìˆ˜ìµë¥  ë¶„ì„...")
    results["event_returns"] = analyze_event_returns(df)

    # ì‹ í˜¸+ì´ë²¤íŠ¸ ê²°í•© íš¨ê³¼
    logger.info("\n[3] ê¸°ìˆ ì  ì‹ í˜¸ + ì´ë²¤íŠ¸ ê²°í•© íš¨ê³¼...")
    results["signal_event"] = analyze_signal_plus_event(df)

    # ì´ë²¤íŠ¸ í›„ íšŒë³µ íŒ¨í„´
    logger.info("\n[4] ì´ë²¤íŠ¸ í›„ íšŒë³µ/ì¶”ê°€í•˜ë½ íŒ¨í„´...")
    results["recovery"] = analyze_event_recovery(df)

    # ì‹¤ì „ ë‰´ìŠ¤ ë°ì´í„° ë¡œë“œ ì‹œë„
    logger.info("\n[5] ì‹¤ì „ ë‰´ìŠ¤ ë¡œê·¸ í™•ì¸...")
    real_news = load_real_news_log(news_log_dir)
    if real_news is not None:
        logger.info("ì‹¤ì „ ë‰´ìŠ¤ ë°ì´í„° ë°œê²¬ â€” ì¶”ê°€ ë¶„ì„ ìˆ˜í–‰")
        results["real_news"] = real_news
        # ì‹¤ì „ ë°ì´í„°ì™€ ì¼ë´‰ ë³‘í•©
        news_merged = real_news.merge(
            daily_df[["ticker", "date", "fwd_ret5", "fwd_ret10"]].assign(
                date=lambda x: x["date"].astype(str)
            ),
            on=["ticker", "date"], how="left"
        )
        if "fwd_ret5" in news_merged.columns:
            for score, label in [(1, "POSITIVE"), (0, "NEUTRAL"),
                                  (-1, "WARNING"), (-2, "CRITICAL")]:
                sub = news_merged[news_merged["news_score"] == score]["fwd_ret5"].dropna()
                if len(sub) >= 5:
                    logger.info(f"  {label}(n={len(sub)}): 5ì¼í›„ í‰ê· ={sub.mean()*100:.2f}%, "
                                f"ìŠ¹ë¥ ={( sub>0).mean()*100:.1f}%")
    else:
        logger.info("  ì‹¤ì „ ë‰´ìŠ¤ ë¡œê·¸ ì—†ìŒ â€” í”„ë¡ì‹œ ë¶„ì„ ê²°ê³¼ë¡œ ëŒ€ì²´")
        logger.info("  (news_monitor.py ì‹¤ì „ ê°€ë™ í›„ ì¬ì‹¤í–‰í•˜ë©´ ì‹¤ì œ ë‰´ìŠ¤Ã—ìˆ˜ìµë¥  ë¶„ì„ ê°€ëŠ¥)")

    # HTML ë¦¬í¬íŠ¸ ìƒì„±
    _generate_news_report(results, event_counts)

    return results


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# 7. HTML ë¦¬í¬íŠ¸
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

def _generate_news_report(results: Dict, event_counts: Dict) -> str:
    from datetime import datetime
    now = datetime.now().strftime("%Y-%m-%d %H:%M")

    def _event_rows():
        df = results.get("event_returns", pd.DataFrame())
        if df.empty:
            return "<tr><td colspan='10'>ë°ì´í„° ì—†ìŒ</td></tr>"
        html = ""
        for _, row in df.iterrows():
            diff = row.get("ì°¨ì´%", 0)
            html += (f"<tr>"
                     f"<td>{row.get('ì´ë²¤íŠ¸')}</td><td>{row.get('ì „ì§„ìˆ˜ìµë¥ ')}</td>"
                     f"<td>{row.get('n_ì´ë²¤íŠ¸')}</td>"
                     f"<td style='color:{'green' if row.get('ì´ë²¤íŠ¸_í‰ê· %',0)>0 else 'red'}'>{row.get('ì´ë²¤íŠ¸_í‰ê· %',0):.2f}%</td>"
                     f"<td>{row.get('ì¼ë°˜_í‰ê· %',0):.2f}%</td>"
                     f"<td style='color:{'green' if diff>0 else 'red'}'>{'+' if diff>0 else ''}{diff:.2f}%</td>"
                     f"<td>{row.get('ì´ë²¤íŠ¸_ìŠ¹ë¥ %',0):.1f}%</td>"
                     f"<td>{row.get('p_value',1):.4f}</td>"
                     f"<td>{row.get('ìœ ì˜','')}</td>"
                     f"</tr>")
        return html

    def _combo_rows():
        df = results.get("signal_event", pd.DataFrame())
        if df.empty:
            return "<tr><td colspan='8'>ë°ì´í„° ì—†ìŒ</td></tr>"
        html = ""
        for _, row in df.iterrows():
            vs = row.get("vs_ê¸°ë³¸ì‹ í˜¸", 0)
            html += (f"<tr>"
                     f"<td><b>{row.get('ì¡°í•©')}</b></td><td>{row.get('n')}</td>"
                     f"<td style='color:{'green' if row.get('í‰ê· ìˆ˜ìµë¥ %',0)>0 else 'red'}'>{row.get('í‰ê· ìˆ˜ìµë¥ %',0):.2f}%</td>"
                     f"<td style='color:{'green' if vs>0 else 'red'}'>{'+' if vs>0 else ''}{vs:.2f}%</td>"
                     f"<td>{row.get('ìŠ¹ë¥ %',0):.1f}%</td>"
                     f"<td>{row.get('p_value',1):.4f}</td>"
                     f"<td>{row.get('ìœ ì˜','')}</td>"
                     f"</tr>")
        return html

    def _recovery_rows():
        df = results.get("recovery", pd.DataFrame())
        if df.empty:
            return "<tr><td colspan='7'>ë°ì´í„° ì—†ìŒ</td></tr>"
        html = ""
        for _, row in df.iterrows():
            html += (f"<tr>"
                     f"<td>{row.get('ì´ë²¤íŠ¸')}</td><td>{row.get('ì „ì§„ê¸°ê°„')}</td>"
                     f"<td>{row.get('n')}</td>"
                     f"<td style='color:{'green' if row.get('í‰ê· ìˆ˜ìµë¥ %',0)>0 else 'red'}'>{row.get('í‰ê· ìˆ˜ìµë¥ %',0):.2f}%</td>"
                     f"<td>{row.get('ëª¨ë©˜í…€ ì§€ì†%',0):.1f}%</td>"
                     f"<td>{row.get('ë˜ëŒë¦¼%',0):.1f}%</td>"
                     f"<td>[{row.get('q25%',0):.1f}%, {row.get('q75%',0):.1f}%]</td>"
                     f"</tr>")
        return html

    event_stat_html = "".join(
        f"<div style='display:inline-block;background:#161b22;border:1px solid #30363d;"
        f"border-radius:8px;padding:12px 20px;margin:5px;text-align:center'>"
        f"<div style='font-size:1.5em;font-weight:bold'>{v:,}</div>"
        f"<div style='color:#8b949e;font-size:.9em'>{k}</div>"
        f"</div>"
        for k, v in event_counts.items()
    )

    html = f"""<!DOCTYPE html>
<html lang="ko"><head><meta charset="UTF-8">
<title>QUANTUM FLOW â€” ë‰´ìŠ¤ ì´ë²¤íŠ¸ ë¶„ì„</title>
<style>
  body{{font-family:'Malgun Gothic',Arial,sans-serif;background:#0d1117;color:#e6edf3;margin:20px}}
  h1{{color:#58a6ff;border-bottom:2px solid #58a6ff;padding-bottom:10px}}
  h2{{color:#79c0ff;margin-top:30px;padding:6px 0 6px 12px;border-left:4px solid #388bfd}}
  table{{border-collapse:collapse;width:100%;margin:12px 0;font-size:.88em}}
  th{{background:#21262d;padding:8px;border:1px solid #30363d;text-align:left}}
  td{{padding:6px 8px;border:1px solid #21262d}}
  tr:hover{{background:#161b22}}
  .sec{{background:#161b22;border-radius:10px;padding:20px;margin:18px 0;border:1px solid #30363d}}
  .note{{background:#1c2128;border-left:4px solid #f0883e;padding:12px 16px;margin:15px 0;
          border-radius:4px;color:#f0883e}}
</style></head><body>

<h1>ğŸ“° QUANTUM FLOW â€” ë‰´ìŠ¤ ì´ë²¤íŠ¸ Ã— ìˆ˜ìµë¥  ë¶„ì„</h1>
<p style="color:#8b949e">ìƒì„±: {now} | ë°©ë²•: ê°€ê²©/ê±°ë˜ëŸ‰ ê¸°ë°˜ ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ</p>

<div class="note">
âš ï¸ í˜„ì¬ ì‹¤ì œ ë‰´ìŠ¤ ë°ì´í„° ì—†ìŒ â€” ê°€ê²©/ê±°ë˜ëŸ‰ íŒ¨í„´ìœ¼ë¡œ ë‰´ìŠ¤ ì´ë²¤íŠ¸ ê·¼ì‚¬<br>
ì‹¤ì „ ë§¤ë§¤ ì‹œì‘ í›„ <code>news_monitor.py</code>ê°€ ë‰´ìŠ¤ë¥¼ ìˆ˜ì§‘í•˜ë©´ ì´ ëª¨ë“ˆë¡œ ì‹¤ì œ ë¶„ì„ ê°€ëŠ¥
</div>

<div class="sec">
<h2>ğŸ“Š ë‰´ìŠ¤ ì´ë²¤íŠ¸ í”„ë¡ì‹œ í†µê³„</h2>
{event_stat_html}
</div>

<div class="sec">
<h2>ğŸ“ˆ ì´ë²¤íŠ¸ ìœ í˜•ë³„ ì „ì§„ìˆ˜ìµë¥  ë¶„í¬ (â˜…=ìœ ì˜, â—†=p&lt;0.10)</h2>
<table>
  <tr><th>ì´ë²¤íŠ¸</th><th>ì „ì§„ê¸°ê°„</th><th>ì´ë²¤íŠ¸N</th><th>ì´ë²¤íŠ¸í‰ê· </th>
      <th>ì¼ë°˜í‰ê· </th><th>ì°¨ì´</th><th>ì´ë²¤íŠ¸ìŠ¹ë¥ </th><th>pê°’</th><th>ìœ ì˜</th></tr>
  {_event_rows()}
</table>
</div>

<div class="sec">
<h2>ğŸ¯ ê¸°ìˆ ì  ì‹ í˜¸ Ã— ì´ë²¤íŠ¸ ê²°í•© íš¨ê³¼ (5ì¼ ì „ì§„ìˆ˜ìµë¥ )</h2>
<p style="color:#8b949e">ì‹ í˜¸ ë°œìƒ ì‹œ ì¶”ê°€ ì´ë²¤íŠ¸ ì¡°ê±´ì´ ìˆ˜ìµë¥ ì— ë¯¸ì¹˜ëŠ” ì˜í–¥</p>
<table>
  <tr><th>ì¡°í•©</th><th>N</th><th>í‰ê· ìˆ˜ìµë¥ </th><th>vsê¸°ë³¸ì‹ í˜¸</th>
      <th>ìŠ¹ë¥ </th><th>pê°’</th><th>ìœ ì˜</th></tr>
  {_combo_rows()}
</table>
</div>

<div class="sec">
<h2>ğŸ”„ ì´ë²¤íŠ¸ í›„ íšŒë³µ/ì¶”ê°€ì´ë™ íŒ¨í„´</h2>
<table>
  <tr><th>ì´ë²¤íŠ¸</th><th>ê¸°ê°„</th><th>N</th><th>í‰ê· ìˆ˜ìµë¥ </th>
      <th>ëª¨ë©˜í…€ ì§€ì†</th><th>ë˜ëŒë¦¼</th><th>IQR [Q1,Q3]</th></tr>
  {_recovery_rows()}
</table>
</div>

<div class="sec">
<h2>ğŸ’¡ ë¶„ì„ ê²°ë¡  ë° ì‹¤ì „ í™œìš© ë°©ì•ˆ</h2>
<h3>í˜„ì¬ (í”„ë¡ì‹œ ê¸°ë°˜)</h3>
<ul>
  <li>ê¸‰ë“±(+5%â†‘) ë‹¹ì¼ ì‹ í˜¸: ì´í›„ 5ì¼ ìˆ˜ìµë¥ ì´ ì¼ë°˜ ì‹ í˜¸ë³´ë‹¤ ë†’ì€ ê²½í–¥ í™•ì¸</li>
  <li>ê¸‰ë½(-5%â†“) í›„ ì§„ì…: íšŒë³µ íŒ¨í„´ ë¶„ì„ìœ¼ë¡œ ì—­ì¶”ì„¸ ì§„ì… ìœ„í—˜ì„± íŒŒì•…</li>
  <li>ê±°ë˜ëŸ‰ í­ì¦(3ë°°â†‘) ì‹ í˜¸: ì •ë³´ ë¹„ëŒ€ì¹­ í•´ì†Œ ê³¼ì • â€” ë°©í–¥ì„± ì¤‘ìš”</li>
</ul>
<h3>ì‹¤ì „ ë‰´ìŠ¤ ìˆ˜ì§‘ í›„ í™œìš© ë°©ì•ˆ</h3>
<ul>
  <li><b>CRITICAL í‚¤ì›Œë“œ ê°ì§€ â†’ ì¦‰ì‹œ ì†ì ˆ</b>: ìƒì¥íì§€, íš¡ë ¹, ë¶„ì‹íšŒê³„ ë“±</li>
  <li><b>WARNING + ê¸°ìˆ ì  ì‹ í˜¸</b>: í¬ì§€ì…˜ ë¹„ì¤‘ 50% ì¶•ì†Œ ê³ ë ¤</li>
  <li><b>POSITIVE + ê¸°ìˆ ì  ì‹ í˜¸</b>: ê¸°ì¡´ ì „ëµ ìœ ì§€ or ë¹„ì¤‘ ì†Œí­ í™•ëŒ€</li>
  <li><b>ë‰´ìŠ¤ ê°ì„± ì ìˆ˜ë¥¼ ADX ëŒ€ì²´ í•„í„°ë¡œ í™œìš©</b>: ë‰´ìŠ¤ ì—†ëŠ” ëŒíŒŒëŠ” ê°€ì§œ ì‹ í˜¸ ê°€ëŠ¥ì„±</li>
</ul>
<h3>ë‹¤ìŒ ë‹¨ê³„</h3>
<ul>
  <li>ì‹¤ì „ ë§¤ë§¤ 2~3ì£¼ í›„ <code>outputs/news_price_log/</code>ì— ë°ì´í„° ì¶•ì </li>
  <li><code>run_news_study(daily_df, news_log_dir="outputs/news_price_log")</code> ì¬ì‹¤í–‰</li>
  <li>ë‰´ìŠ¤ ê°ì„± Ã— 5ì¼ ìˆ˜ìµë¥  ìƒê´€ê´€ê³„ ì‹¤ì œ ì¸¡ì • â†’ ê°€ì¤‘ì¹˜ ì ìš© ì—¬ë¶€ ê²°ì •</li>
</ul>
</div>

<p style="color:#555;text-align:center;margin-top:40px">QUANTUM FLOW v2.1 News Study | {now}</p>
</body></html>"""

    out = OUT_DIR / "news_study_report.html"
    out.write_text(html, encoding="utf-8")
    logger.info(f"[ë‰´ìŠ¤ ë¦¬í¬íŠ¸] ì €ì¥: {out}")
    return str(out)


# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•
# ë©”ì¸ ì‹¤í–‰
# â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•â•

if __name__ == "__main__":
    import os, sys
    sys.path.insert(0, str(Path(__file__).parent.parent))
    os.chdir(Path(__file__).parent.parent)

    logging.basicConfig(level=logging.INFO,
                        format="%(asctime)s [%(name)s] %(message)s")

    from data_prep import load_daily_data
    print("ë°ì´í„° ë¡œë”©...")
    df = load_daily_data(start_date="20230901", top_n_tickers=800, min_days=60)
    print(f"ë¡œë“œ ì™„ë£Œ: {len(df):,}í–‰, {df['ticker'].nunique()}ì¢…ëª©")

    results = run_news_study(df)
    print(f"\në‰´ìŠ¤ ë¶„ì„ ì™„ë£Œ! ê²°ê³¼: analysis/results/extended/news_study_report.html")
